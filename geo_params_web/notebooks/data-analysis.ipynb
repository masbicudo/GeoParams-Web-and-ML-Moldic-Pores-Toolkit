{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae46cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import libs.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a112ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import libs.plot_context as pc\n",
    "import localizable_resources as lr\n",
    "\n",
    "def reload_libs_env():\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\".env\", override=True)\n",
    "\n",
    "    reload(pc)\n",
    "    reload(lr)\n",
    "\n",
    "reload_libs_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sizes = pc.rc_sizes(16, 21, 24, [8, 8])\n",
    "MyPlot = pc.create_plot_context(global_sizes, reload_libs_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.load_data_from_files(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb6fc88",
   "metadata": {},
   "source": [
    "# User comments\n",
    "\n",
    "Nessa seção vou analisar as principais reclamações e sugestões dos usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910cdee",
   "metadata": {},
   "source": [
    "## Principais Reclamações e Sugestões dos Usuários\n",
    "\n",
    "Esse resumo foi gerado pelo Chat GPT 5, copiando os reviews dos usuários encontrados e exibidos anteriormente.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Reconhecimento e Conexões de Poros\n",
    "- Poros grandes às vezes são divididos indevidamente em dois.  \n",
    "- Poros menores nem sempre são identificados.  \n",
    "- Alguns poros desconectados aparecem como conectados na segmentação.  \n",
    "- Microporosidade não detectada.  \n",
    "- Falta detecção de poros muito pequenos (< 100 pixels).  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Interface e Compreensão dos Parâmetros\n",
    "- Dificuldade para entender as cores no espaço de parâmetros.  \n",
    "- Falta de clareza sobre o significado dos eixos X e Y da segmentação.  \n",
    "- Texto explicativo para seleção de pixels pouco claro.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Problemas de Recorte e Correspondência de Imagens\n",
    "- Cortes na fotomicrografia que geram discrepâncias com a imagem segmentada.  \n",
    "- Diferença entre imagens recortadas e segmentadas dependendo do formato do recorte (quadrado, retangular horizontal/vertical).  \n",
    "- Barra lateral impedindo clique em parte da imagem.  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. Considerações sobre Bolhas\n",
    "- Bolhas foram bem reconhecidas, mas também representam porosidade e precisam ser consideradas na análise para evitar subestimativa.  \n",
    "\n",
    "---\n",
    "\n",
    "### 5. Ajustes Técnicos Sugeridos\n",
    "- Permitir modificar o tamanho mínimo de pixels para detecção.  \n",
    "- Melhorar isolamento de bolhas sem perder detecção de poros menores. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5dd85",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df\n",
    "filtered_df = filtered_df[\n",
    "            ~filtered_df['canceled']\n",
    "            & ~filtered_df[\"name\"].str.contains(\"Test\", case=False, na=False)]\n",
    "items_by_email = filtered_df.groupby(\"email\").size().sort_values(ascending=False)\n",
    "print(f\"Number of unique emails: {len(items_by_email)}\")\n",
    "items_by_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique reviews per file:\")\n",
    "mask = df['review'].notna() & df['review'].astype(str).str.strip().ne('')\n",
    "df_clean = df[mask]\n",
    "df_clean.groupby(\"filename\")[\"review\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique users per file:\")\n",
    "df.groupby(\"filename\")[\"email\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a97b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total non-canceled 'clicks' per file:\")\n",
    "mask = ~df['canceled']\n",
    "df_clean = df[mask]\n",
    "df_clean[\"filename\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total canceled items, and associated files (should not exist?):\")\n",
    "df[df[\"canceled\"]][\"filename\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ae65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total canceled items, and associated files (should not exist?):\")\n",
    "df.groupby(\"filename\")[\"folder_name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad85ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def compute_group_stats(df):\n",
    "    groups = sorted(df[\"experience\"].unique())\n",
    "    K_means, K_ci = [], []\n",
    "    C_means, C_ci = [], []\n",
    "\n",
    "    for g in groups:\n",
    "        sub = df[df[\"experience\"] == g]\n",
    "        K = sub[\"clicked_x\"].to_numpy()\n",
    "        C = sub[\"clicked_y\"].to_numpy()\n",
    "\n",
    "        # Means\n",
    "        K_means.append(K.mean())\n",
    "        C_means.append(C.mean())\n",
    "\n",
    "        # Standard errors (for CI)\n",
    "        K_ci.append(1.96 * K.std(ddof=1) / np.sqrt(len(K)))\n",
    "        C_ci.append(1.96 * C.std(ddof=1) / np.sqrt(len(C)))\n",
    "\n",
    "    return groups, K_means, K_ci, C_means, C_ci\n",
    "\n",
    "\n",
    "def plot_group_bars(ax, groups, means, ci, ylabel, title):\n",
    "\n",
    "    ax.bar(groups, means, yerr=ci, capsize=6)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(\"Experience Level\")\n",
    "    ax.set_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups, K_means, K_ci, C_means, C_ci = compute_group_stats(filtered_df)\n",
    "name = \"K_bar_chart\"\n",
    "with MyPlot(f\"images/{name}.pdf\", figsize=[10, 6]) as mp:\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plot_group_bars(\n",
    "        ax,\n",
    "        groups, K_means, K_ci,\n",
    "        ylabel=\"K_max\",\n",
    "        title=\"Inter-group variability in K_max\",\n",
    "    )\n",
    "\n",
    "name = \"C_bar_chart\"\n",
    "with MyPlot(f\"images/{name}.pdf\", figsize=[10, 6]) as mp:\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plot_group_bars(\n",
    "        ax,\n",
    "        groups, C_means, C_ci,\n",
    "        ylabel=\"C_min\",\n",
    "        title=\"Inter-group variability in C_min\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_distance_matrix(df):\n",
    "    groups = sorted(df[\"experience\"].unique())\n",
    "    G = len(groups)\n",
    "    D = np.zeros((G, G))\n",
    "\n",
    "    for i, g1 in enumerate(groups):\n",
    "        for j, g2 in enumerate(groups):\n",
    "            u1 = df[df[\"experience\"] == g1]\n",
    "            u2 = df[df[\"experience\"] == g2]\n",
    "\n",
    "            Theta1 = np.vstack([u1[\"clicked_x\"], u1[\"clicked_y\"]]).T\n",
    "            Theta2 = np.vstack([u2[\"clicked_x\"], u2[\"clicked_y\"]]).T\n",
    "\n",
    "            # pairwise distances\n",
    "            dd = np.sqrt(((Theta1[:, None, :] - Theta2[None, :, :]) ** 2).sum(axis=2))\n",
    "            D[i, j] = dd.mean()\n",
    "\n",
    "    return groups, D\n",
    "\n",
    "\n",
    "def plot_distance_heatmap(ax, groups, D):\n",
    "\n",
    "    cax = ax.imshow(D, cmap=\"viridis\")\n",
    "    fig = ax.get_figure()\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "\n",
    "    ax.set_xticks(range(len(groups)))\n",
    "    ax.set_yticks(range(len(groups)))\n",
    "    ax.set_xticklabels(groups)\n",
    "    ax.set_yticklabels(groups)\n",
    "\n",
    "    ax.set_xlabel(\"Experience Level\")\n",
    "    ax.set_ylabel(\"Experience Level\")\n",
    "    ax.set_title(\"Inter-group Parameter Distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups, D = compute_group_distance_matrix(filtered_df)\n",
    "name = \"group_distances\"\n",
    "with MyPlot(f\"images/{name}.pdf\", figsize=[10, 6]) as mp:\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plot_distance_heatmap(\n",
    "        ax,\n",
    "        groups, D,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394405fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filtered_df[\"email\"].value_counts()))\n",
    "display(filtered_df.groupby(\"experience\").get_group(5)[\"email\"].value_counts())\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import libs.plots as plots\n",
    "\n",
    "USE_COLOR_BAR = True\n",
    "SHOW_MEANS = False\n",
    "SHOW_DISPERSION = True\n",
    "SHOW_AGGREGATION = True\n",
    "SHOW_EXP_LEVELS = [1, 2, 3, 4, 5]\n",
    "USE_CANCELED_OR_TESTS = False\n",
    "\n",
    "name = \"best_color_params\"\n",
    "with MyPlot(f\"images/{name}.pdf\", figsize=[12, 8]) as mp:\n",
    "\n",
    "    # Filter data based on user input\n",
    "    filtered_df = df.sort_values(by=[\"experience\"])\n",
    "\n",
    "    if not USE_CANCELED_OR_TESTS:\n",
    "        filtered_df = filtered_df[\n",
    "            ~filtered_df['canceled']\n",
    "            & ~filtered_df[\"name\"].str.contains(\"Test\", case=False, na=False)]\n",
    "\n",
    "    # Plot the clicked points\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plots.plot_best_color_params(\n",
    "        ax, filtered_df,\n",
    "        use_color_bar=USE_COLOR_BAR,\n",
    "        show_means=SHOW_MEANS,\n",
    "        show_dispersion=SHOW_DISPERSION,\n",
    "        show_exp_levels=SHOW_EXP_LEVELS,\n",
    "        show_aggregation=SHOW_AGGREGATION,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ba147",
   "metadata": {},
   "source": [
    "# Locating cropped regions in source images\n",
    "\n",
    "The web application was not saving the information of where the cropped images came from.\n",
    "\n",
    "What we have at the moment are:\n",
    "- the cropped image saved in JPEG format, and resized to 1/8 of the size in each dimension\n",
    "- the options.json file containing the name of the original image\n",
    "\n",
    "What we need to do to:\n",
    "- load the cropped image, and resize it to 8 times in each dimension\n",
    "- use a function to search the cropped image by image similarity inside the original image\n",
    "- draw a box over the original image to indicate the source of the cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def search_subimage_in_main_image(cropped, original):\n",
    "    \"\"\"\n",
    "    Function to search for a cropped image within the original image.\n",
    "    \n",
    "    Args:\n",
    "        cropped: The cropped image (cv2 image)\n",
    "        original: The original image (cv2 image)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with match information\n",
    "    \"\"\"\n",
    "    # Convert both to grayscale for matching\n",
    "    original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "    crop_small_gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    scale_factor = 8\n",
    "    crop_upscaled = cv2.resize(crop_small_gray, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Template matching\n",
    "    res = cv2.matchTemplate(original_gray, crop_upscaled, cv2.TM_CCOEFF_NORMED)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    \n",
    "    return {\n",
    "        'max_val': max_val,\n",
    "        'top_left': max_loc,\n",
    "        'cropped_shape': crop_upscaled.shape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af6ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cropped_file = \"static/output/14ec62b9-586b-4e30-92ba-c75111a54212/0/cropped.jpg\"\n",
    "original_image_file = 'static/imgs_sections/2-SMC-1-AL_72,99m_n=_2,5x_cesc.jpg'\n",
    "cropped_image = cv2.imread(cropped_file)\n",
    "original_image = cv2.imread(original_image_file)\n",
    "\n",
    "plt.imshow(cropped_image[:, :, ::-1])\n",
    "plt.show()\n",
    "\n",
    "result = search_subimage_in_main_image(cropped_image, original_image)\n",
    "top_left = result['top_left']\n",
    "cropped_shape = result['cropped_shape']\n",
    "\n",
    "# Draw rectangle on the original image\n",
    "cv2.rectangle(original_image, top_left, (top_left[0] + cropped_shape[1], top_left[1] + cropped_shape[0]), (255, 255, 255), 20)\n",
    "\n",
    "plt.imshow(original_image[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to the original image\n",
    "original_image_path = {\n",
    "    \"2-SMC-1-AL_72,99m_n=_2,5x_cesc.jpg\": 'static/imgs_sections/2-SMC-1-AL_72,99m_n=_2,5x_cesc.jpg',\n",
    "    \"2-SMC-1-AL_73,97m_n=_2,5x_cesc.jpg\": 'static/imgs_sections/2-SMC-1-AL_73,97m_n=_2,5x_cesc.jpg',\n",
    "    \"72.53_jpeg_escal.jpg\": 'static/imgs_sections/72.53_jpeg_escal.jpg',\n",
    "}\n",
    "original_image = {}\n",
    "\n",
    "# Load the original image once\n",
    "for k in original_image_path:\n",
    "    try:\n",
    "        original_image[k] = cv2.imread(original_image_path[k])\n",
    "        if original_image[k] is None:\n",
    "            print(f\"Could not load original image: {original_image_path[k]}\")\n",
    "        else:\n",
    "            print(f\"Loaded original image: {k} with shape {original_image[k].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading original image: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ad045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Use glob to find all cropped images\n",
    "cropped_pattern = 'static/output/*/*/cropped.jpg'\n",
    "cropped_files = glob.glob(cropped_pattern)\n",
    "\n",
    "print(f\"Found {len(cropped_files)} cropped images\")\n",
    "\n",
    "RESET_CROPPED_INFO_FILES = False\n",
    "\n",
    "results = []  # Store results for each cropped image\n",
    "# Iterate over each cropped image\n",
    "for cropped_file in cropped_files:\n",
    "    try:\n",
    "        # Load the cropped image\n",
    "        cropped_image = cv2.imread(cropped_file)\n",
    "        path = os.path.dirname(cropped_file)\n",
    "        if RESET_CROPPED_INFO_FILES:\n",
    "            os.remove(f'{path}/cropped.json')  # Remove the cropped file to reset it\n",
    "        if os.path.exists(f'{path}/cropped.json'):\n",
    "            print(f\"Skipping already processed file: {cropped_file}\")\n",
    "            with open(f'{path}/cropped.json', 'r') as f:\n",
    "                result = json.load(f)\n",
    "            results.append(result)\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing file: {cropped_file}\")\n",
    "        options_file = f'{path}/options.json'\n",
    "        with open(options_file, 'r') as f:\n",
    "            options = json.load(f)\n",
    "            \n",
    "        source_image_key = options[\"image_select.filename\"]\n",
    "        source_image = original_image.get(source_image_key, None)\n",
    "        \n",
    "        if cropped_image is None:\n",
    "            print(f\"Could not load cropped image: {cropped_file}\")\n",
    "            continue\n",
    "            \n",
    "        # Apply the function\n",
    "        result = search_subimage_in_main_image(cropped_image, source_image)\n",
    "        \n",
    "        # Store results with file path\n",
    "        result['cropped_file'] = cropped_file.replace('\\\\', '/')\n",
    "        results.append(result)\n",
    "        \n",
    "        with open(f'{path}/cropped.json', 'w') as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "        \n",
    "        print(f\"Processed {cropped_file}: match_value={result['max_val']:.4f}, position={result['top_left']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cropped_file}: {e}\")\n",
    "\n",
    "print(f\"Processed (or loaded info about) {len(results)} cropped images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17470091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for it, result in enumerate(results):\n",
    "    cropped_file = result[\"cropped_file\"]\n",
    "    path = os.path.dirname(cropped_file)\n",
    "    \n",
    "    subimage_file = f'{path}/cropped_original_size.jpg'\n",
    "    if os.path.exists(subimage_file):\n",
    "        print(f\"Subimage already exists: {subimage_file}\")\n",
    "        continue\n",
    "    \n",
    "    options_file = f'{path}/options.json'\n",
    "    with open(options_file, 'r') as f:\n",
    "        options = json.load(f)\n",
    "    source_image_key = options[\"image_select.filename\"]\n",
    "    \n",
    "    top_left = result['top_left']\n",
    "    cropped_shape = result['cropped_shape']\n",
    "    \n",
    "    x, y = top_left\n",
    "    h, w = cropped_shape[:2]\n",
    "    subimage = original_image[source_image_key][y:y+h, x:x+w]\n",
    "\n",
    "    # Save the subimage\n",
    "    cv2.imwrite(subimage_file, subimage)\n",
    "    print(f\"Saved subimage for {cropped_file} at {subimage_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec49285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from libs.colors import parse_color\n",
    "\n",
    "SHOW_CROPPED_IMAGES = False\n",
    "\n",
    "# 0 -> use white rectangles\n",
    "# 1 -> use colored rectangles\n",
    "# 2 -> use experience levels as colors from the colormap\n",
    "USE_RECTANGLE_COLORS = 0\n",
    "\n",
    "USE_COLOR_MAP = 'rainbow'\n",
    "\n",
    "# Use the notebook slim-section-rects-interactive-visualizer.ipynb\n",
    "# to select the rectangles to show\n",
    "SPECIAL_RECTANGLES = {\n",
    "    # When more users are added, the numeric indices must be updated.\n",
    "    # TODO: We should probably use guid and session number instead of indices.\n",
    "    # 2: 'purple',\n",
    "    # # 22: 'red',\n",
    "    # 32: 'red',\n",
    "    # 35: 'green',\n",
    "}\n",
    "\n",
    "LINE_WIDTH = 30#20  # Width of the rectangle lines\n",
    "\n",
    "original_image_copy = {}\n",
    "for k in original_image_path:\n",
    "    original_image_copy[k] = original_image[k].copy()\n",
    "\n",
    "cmap = plt.get_cmap(USE_COLOR_MAP, len(results))\n",
    "\n",
    "count_non_canceled = 0\n",
    "for it, result in enumerate(results):\n",
    "    cropped_file = result[\"cropped_file\"]\n",
    "    path = os.path.dirname(cropped_file)\n",
    "    \n",
    "    if os.path.exists(f'{path}/params_select.state=Cancel'):\n",
    "        print(f\"Skipping canceled image {cropped_file}.\")\n",
    "        continue\n",
    "    \n",
    "    options_file = f'{path}/options.json'\n",
    "    with open(options_file, 'r') as f:\n",
    "        options = json.load(f)\n",
    "    source_image_key = options[\"image_select.filename\"]\n",
    "    \n",
    "    canceled = data.is_option_canceled(options)\n",
    "    test = data.is_option_test(options)\n",
    "    if canceled or test:\n",
    "        print(f\"Skipping canceled or test image {cropped_file}.\")\n",
    "        continue\n",
    "\n",
    "    # if source_image_key != \"2-SMC-1-AL_72,99m_n=_2,5x_cesc.jpg\":\n",
    "    #     print(f\"Skipping image {cropped_file} as it is not the target image.\")\n",
    "    #     continue\n",
    "\n",
    "    top_left = result['top_left']\n",
    "    cropped_shape = result['cropped_shape']\n",
    "    \n",
    "    # Draw rectangle on the original image\n",
    "    if it in SPECIAL_RECTANGLES:\n",
    "        rgba_color = parse_color(SPECIAL_RECTANGLES[it], cmap)  # Returns (R, G, B, A) in 0-1 range\n",
    "    elif USE_RECTANGLE_COLORS == 1:\n",
    "        rgba_color = cmap(((it * 97) % len(results)) / len(results))  # Returns (R, G, B, A) in 0-1 range\n",
    "    elif USE_RECTANGLE_COLORS == 2:\n",
    "        experience = options[\"user\"][\"experience\"]\n",
    "        rgba_color = cmap((experience - 1) / 5)  # Returns (R, G, B, A) in 0-1 range\n",
    "    else:\n",
    "        rgba_color = (1, 1, 1, 1)  # White color in RGBA\n",
    "    bgr_color = (int(rgba_color[2] * 255), int(rgba_color[1] * 255), int(rgba_color[0] * 255))  # Convert to BGR 0-255\n",
    "    \n",
    "    cv2.rectangle(original_image_copy[source_image_key],\n",
    "                  top_left,\n",
    "                  (top_left[0] + cropped_shape[1], top_left[1] + cropped_shape[0]),\n",
    "                  bgr_color,  # Use BGR color tuple\n",
    "                  LINE_WIDTH)\n",
    "\n",
    "    if SHOW_CROPPED_IMAGES:\n",
    "        cropped_image = cv2.imread(result['cropped_file'])\n",
    "        plt.imshow(cropped_image[:, :, ::-1])  # Convert BGR to RGB for display\n",
    "        print(f\"Cropped Image: {result['cropped_file']}\")\n",
    "        plt.show()\n",
    "    \n",
    "    count_non_canceled += 1\n",
    "    # break\n",
    "\n",
    "print(f\"Processed {count_non_canceled} non-canceled cropped images.\")\n",
    "\n",
    "plt.imshow(original_image_copy[\"2-SMC-1-AL_72,99m_n=_2,5x_cesc.jpg\"][:, :, ::-1])  # Convert BGR to RGB for display\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e755bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in original_image_copy.keys():\n",
    "    name, ext = os.path.splitext(key)\n",
    "    cv2.imwrite(f'images/found_cropped_areas_{name}.jpg', original_image_copy[key])\n",
    "    import libs.images as images\n",
    "    images.resize_image_file(\n",
    "        f'images/found_cropped_areas_{name}.jpg',\n",
    "        f'images/found_cropped_areas_{name}_small.jpg',\n",
    "        percentage=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340cc73",
   "metadata": {},
   "source": [
    "# Creating large versions of the parameter-space and isolating the segmentation of each clicked point\n",
    "\n",
    "1. Large version of the parameter-space\n",
    "   - this will show where the user clicked\n",
    "2. Isolating the segmentation of each clicked point\n",
    "   - For each click in the parameter-space, save the associated segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79942184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from skimage.measure import label, regionprops\n",
    "from libs.images import binarize_c_k, regions_df, rmm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "REPROCESS_BIG_IMAGES = False\n",
    "\n",
    "SEGMENT_IN_ORIGINAL_SIZE = False  # If True, segment the original size image, otherwise use segmented small image\n",
    "\n",
    "for it, result in enumerate(results):\n",
    "    cropped_file = result[\"cropped_file\"]\n",
    "    path = os.path.dirname(cropped_file)\n",
    "    \n",
    "    params_space_img_file = f'{path}/main_image.png'\n",
    "    big_params_space_img_file = f'{path}/main_image_big.png'\n",
    "    if REPROCESS_BIG_IMAGES:\n",
    "        if os.path.exists(big_params_space_img_file):\n",
    "            os.remove(big_params_space_img_file)\n",
    "    if os.path.exists(big_params_space_img_file):\n",
    "        print(f\"Big image already exists: {big_params_space_img_file}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Big image processing: {big_params_space_img_file}\")\n",
    "    \n",
    "    clicks_file = f'{path}/clicked_points.json'\n",
    "    if not os.path.exists(clicks_file):\n",
    "        print(f\"Clicked points file not found: {clicks_file}\")\n",
    "        continue\n",
    "    with open(clicks_file, 'r') as f:\n",
    "        clicks_data = json.load(f)\n",
    "    \n",
    "    params_space_image = cv2.imread(params_space_img_file)\n",
    "    params_space_image_big = cv2.resize(params_space_image, None, fx=8, fy=8, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Save the subimage\n",
    "    plt.imshow(params_space_image_big[:, :, ::-1])  # Convert BGR to RGB for display\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    # Keep spines (the box) visible\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "\n",
    "    \n",
    "    for click in clicks_data[\"points\"]:\n",
    "        x = click['x']*8\n",
    "        y = click['y']*8\n",
    "        ax.plot(x, y, marker='x', color='orange', markersize=24, mew=6, linestyle='None')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(big_params_space_img_file)\n",
    "    plt.close()\n",
    "    \n",
    "    # extracting the clicked points segmentation\n",
    "    if SEGMENT_IN_ORIGINAL_SIZE:\n",
    "        cropped_file = f'{path}/cropped_original_size.jpg'\n",
    "        cropped_image = cv2.imread(cropped_file)\n",
    "        cropped_image = cropped_image.astype(np.uint8)  # Ensure correct dtype\n",
    "        \n",
    "        colors = [\n",
    "                np.array([0, 0, 0]),\n",
    "                np.array([0, 0, 255]),\n",
    "                np.array([255, 0, 0]),\n",
    "                np.array([0, 255, 0]),\n",
    "                np.array([255, 255, 255]),\n",
    "            ]\n",
    "\n",
    "        thresh = clicks_data[\"min_pore_size\"]*8*8 # Convert to pixels in the big image\n",
    "        for click in clicks_data[\"points\"]:\n",
    "            k = click['x']*8\n",
    "            c = click['y']*8\n",
    "            \n",
    "            label_img, regions = binarize_c_k(cropped_image, c, k)\n",
    "            regions = regionprops(label_img)\n",
    "            df = regions_df(regions, label_img)\n",
    "            \n",
    "            bin_image_4 = np.zeros((*label_img.shape, 3), dtype=np.uint8)\n",
    "            id_region = 0\n",
    "            for it, region in enumerate(regions):\n",
    "                #display(df)\n",
    "                if df[\"area\"].iloc[it] > thresh:\n",
    "                    id_region += 1\n",
    "                    #color_value = np.array([255, 255, 255])\n",
    "                    color_value = colors[rmm(id_region, 0, len(colors)-1)]\n",
    "                    bin_image_4[region.coords.T[0], region.coords.T[1]] = color_value\n",
    "            # Save the subimage\n",
    "            cv2.imwrite(f'{path}/segmentation_x={int(k/8)}_y={int(c/8)}.png', bin_image_4)\n",
    "    \n",
    "    else:\n",
    "        tiles_file = f'{path}/stitched_tiles.png'\n",
    "        tiles_image = cv2.imread(tiles_file)\n",
    "        \n",
    "        cropped_file = f'{path}/cropped.jpg'\n",
    "        cropped_image = cv2.imread(cropped_file)\n",
    "        \n",
    "        tile_height, tile_width = cropped_image.shape[:2]\n",
    "        \n",
    "        for click in clicks_data[\"points\"]:\n",
    "            x = click['x']\n",
    "            y = click['y']\n",
    "            \n",
    "            if x >= 0 and y >= 0:\n",
    "                \n",
    "                tile_image = tiles_image[y*tile_height:(y+1)*tile_height, x*tile_width:(x+1)*tile_width]\n",
    "                # Save the subimage\n",
    "                cv2.imwrite(f'{path}/segmentation_x={x}_y={y}.png', tile_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36542fa3",
   "metadata": {},
   "source": [
    "# Calculating porosity and number of pores for the segmentation of each click in parameters-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a7179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "\n",
    "columns = [\"source_image_key\",\"x\",\"y\",\"canceled\",\"sz_kind\",\n",
    "           \"cut_kind\",\"porosity\",\"pore_count\",\"experience\",\n",
    "           \"image_hash\"]\n",
    "\n",
    "def compute_hash_from_image(image):\n",
    "    \"\"\"Compute a hash for a given image (numpy array).\"\"\"\n",
    "    image_bytes = image.tobytes()\n",
    "    return hashlib.sha256(image_bytes).hexdigest()\n",
    "\n",
    "if os.path.exists('static/output/clicks_data.csv'):\n",
    "    print(\"Cached clicks data file found\")\n",
    "    df_clicks = pd.read_csv('static/output/clicks_data.csv')\n",
    "    for col in columns:\n",
    "        if col not in df_clicks.columns:\n",
    "            df_clicks[col] = pd.NA\n",
    "    df_clicks = df_clicks[columns]\n",
    "else:\n",
    "    df_clicks = pd.DataFrame(columns=columns)  # Initialize empty DataFrame\n",
    "\n",
    "# Use glob to find all cropped images\n",
    "options_file_pattern = 'static/output/*/*/options.json'\n",
    "options_files = glob.glob(options_file_pattern)\n",
    "\n",
    "print(f\"Found {len(options_files)} options files\")\n",
    "\n",
    "full_img_hashes = {}\n",
    "triplet_to_row = {}\n",
    "for idx, row in df_clicks.iterrows():\n",
    "    if row[\"cut_kind\"] == \"full\" and isinstance(row[\"image_hash\"], str) and row[\"image_hash\"] != \"\":\n",
    "        full_img_hashes[(row[\"source_image_key\"], row[\"sz_kind\"])] = row[\"image_hash\"]\n",
    "    key = (row[\"image_hash\"], row[\"x\"], row[\"y\"])\n",
    "    if key not in triplet_to_row:\n",
    "        triplet_to_row[key] = (*row[[\"porosity\", \"pore_count\"]].values,)\n",
    "\n",
    "\n",
    "clicks_data = []\n",
    "pbar = tqdm(options_files)\n",
    "for options_file in pbar:\n",
    "    path = os.path.dirname(options_file)\n",
    "    \n",
    "    with open(options_file, 'r') as f:\n",
    "        options = json.load(f)\n",
    "    \n",
    "    if \"image_select.filename\" not in options:\n",
    "        pbar.set_description(f\"No image_select.filename in {options_file}\")\n",
    "        continue\n",
    "    \n",
    "    pbar.set_description(f\"Processing file: {options_file}\")\n",
    "    \n",
    "    source_image_key = options[\"image_select.filename\"]\n",
    "    \n",
    "    for click in options.get(\"params_select.clicked_points\", []):\n",
    "        if isinstance(click, dict) and \"x\" in click and \"y\" in click:\n",
    "            \n",
    "            \n",
    "            # Loading image files for segmentation\n",
    "            big_cropped_file = f'{path}/cropped_original_size.jpg'\n",
    "            small_source_file = f'static/imgs_sections/12.5/{source_image_key}'\n",
    "            small_cropped_file = f'{path}/cropped.jpg'\n",
    "    \n",
    "            big_source_image = original_image[source_image_key]\n",
    "            big_cropped_image = cv2.imread(big_cropped_file)\n",
    "            small_source_image = cv2.imread(small_source_file)\n",
    "            small_cropped_image = cv2.imread(small_cropped_file)\n",
    "            \n",
    "            all_files = [\n",
    "                (big_source_image, \"big\", \"full\", f\"{source_image_key}\"),\n",
    "                (big_cropped_image, \"big\", \"cropped\", big_cropped_file),\n",
    "                (small_source_image, \"small\", \"full\", small_source_file),\n",
    "                (small_cropped_image, \"small\", \"cropped\", small_cropped_file),\n",
    "                ]\n",
    "            \n",
    "            for img, sz, cut, fname in all_files:\n",
    "                if img is None:\n",
    "                    print(f\"Could not load image: {fname}\")\n",
    "                    continue\n",
    "                \n",
    "                if cut == \"full\" and (source_image_key, sz) in full_img_hashes:\n",
    "                    image_hash = full_img_hashes[(source_image_key, sz)]\n",
    "                else:\n",
    "                    image_hash = compute_hash_from_image(img)\n",
    "                key = (image_hash, click['x'], click['y'])\n",
    "                \n",
    "                if key in triplet_to_row:\n",
    "                    pbar.set_description(f\"Using cached data for key: {key}\")\n",
    "                    porosity, pore_count = triplet_to_row[key]\n",
    "                else:\n",
    "                    pbar.set_description(f\"Computing segmentation for key: {key}\")\n",
    "                    k = click['x']*8\n",
    "                    c = click['y']*8\n",
    "                    binaryImage = cv2.inRange(\n",
    "                        img,\n",
    "                        ( c,   0,   0,   0),\n",
    "                        (255, 255,  64, k))\n",
    "                    \n",
    "                    label_img = label(binaryImage)\n",
    "                    regions = regionprops(label_img)\n",
    "                    \n",
    "                    total_area = sum(region.area for region in regions)\n",
    "                    h, w = label_img.shape\n",
    "                    porosity = total_area / (h * w) if (h * w) > 0 else 0\n",
    "                    pore_count = len(regions)\n",
    "                    \n",
    "                    triplet_to_row[key] = (porosity, pore_count)\n",
    "                    if cut == \"full\" and isinstance(image_hash, str) and image_hash != \"\":\n",
    "                        full_img_hashes[(source_image_key, sz)] = image_hash\n",
    "\n",
    "                # Append the click data and associated segmentation metrics\n",
    "                clicks_data.append({\n",
    "                    'source_image_key': source_image_key,\n",
    "                    'x': click['x'],\n",
    "                    'y': click['y'],\n",
    "                    'canceled': options.get(\"params_select.state\", \"\") == \"Cancel\",\n",
    "                    'sz_kind': sz,\n",
    "                    'cut_kind': cut,\n",
    "                    'porosity': porosity,\n",
    "                    'pore_count': pore_count,\n",
    "                    'experience': options[\"user\"][\"experience\"],\n",
    "                    \"image_hash\": image_hash,\n",
    "                })\n",
    "\n",
    "df_clicks = pd.DataFrame(clicks_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks.to_csv('static/output/clicks_data.csv', float_format=\"%.15f\", index=False)\n",
    "df_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_porosity_distribution_arrow(df_clicks, data_field=\"porosity\", sz_kind=\"small\", cut_kind=\"full\", \n",
    "                                       show_extension_lines=True, extension_factor=0.1,\n",
    "                                       extension_style='--', extension_alpha=0.7,\n",
    "                                       legends_offsets=None, exp_levels=None,\n",
    "                                       arrow_locs=None,\n",
    "                                       title=None, x_label=None,\n",
    "                                       clip_min_x=0, plot_width=10, plot_height=6,\n",
    "                                       remove_y_axis=False):\n",
    "    \"\"\"\n",
    "    Plot CDF with extended horizontal lines after reaching 100% probability.\n",
    "    \n",
    "    Parameters:\n",
    "    - show_extension_lines: Whether to show dashed lines extending the CDF\n",
    "    - extension_factor: How much to extend beyond max value (0.1 = 10%)\n",
    "    - extension_style: Line style for extensions ('--', ':', '-', etc.)\n",
    "    - extension_alpha: Transparency of extension lines\n",
    "    \"\"\"\n",
    "    df_work = df_clicks[\n",
    "                (df_clicks[\"source_image_key\"] == \"2-SMC-1-AL_72,99m_n=_2,5x_cesc.jpg\")\n",
    "            & (df_clicks[\"canceled\"] == False)\n",
    "            & (df_clicks[\"sz_kind\"] == sz_kind)\n",
    "            & (df_clicks[\"cut_kind\"] == cut_kind)\n",
    "            ]\n",
    "    \n",
    "    name = f\"cdf_{data_field}_by_experience_sz={sz_kind}_cut={cut_kind}_extended\"\n",
    "    print(f\"FILE_NAME = images/{name}.pdf\")\n",
    "    with MyPlot(f\"images/{name}.pdf\", figsize=[plot_width, plot_height]) as mp:\n",
    "\n",
    "        print(f\"sz={sz_kind}\\ncut={cut_kind}\")\n",
    "\n",
    "        # Plot CDF for different experience levels\n",
    "        plt.figure()\n",
    "\n",
    "        # Find the overall maximum value for extending the plot\n",
    "        all_data = df_work[data_field]\n",
    "        global_max = all_data.max() if len(all_data) > 0 else 1.0\n",
    "        extended_max = global_max * (1 + extension_factor)\n",
    "\n",
    "        # Store colors for consistent extension lines\n",
    "        colors = {}\n",
    "        \n",
    "        if exp_levels is None:\n",
    "            exp_levels = [2, 3, 4, 5]\n",
    "\n",
    "        for exp in exp_levels:\n",
    "            data = df_work[df_work[\"experience\"] == exp][data_field]\n",
    "            \n",
    "            if len(data) > 0:\n",
    "                # Plot the main CDF and capture the line object to get its color\n",
    "                line = sns.ecdfplot(data, label=lr.str.experience_level(exp), linewidth=3)\n",
    "                \n",
    "                # Get the color of the last plotted line\n",
    "                color = plt.gca().lines[-1].get_color()\n",
    "                colors[exp] = color\n",
    "                \n",
    "                if show_extension_lines:\n",
    "                    # Get the maximum value for this experience level\n",
    "                    exp_max = data.max()\n",
    "                    \n",
    "                    # Add horizontal extension line\n",
    "                    plt.plot([exp_max, extended_max], [1.0, 1.0], \n",
    "                            color=color, linewidth=3, linestyle=extension_style, \n",
    "                            alpha=extension_alpha)\n",
    "\n",
    "        if global_max > 10000:\n",
    "            def thousands_formatter(x, pos):\n",
    "                return f\"{int(x/1000)}k\"\n",
    "            plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(thousands_formatter))\n",
    "        \n",
    "        if legends_offsets is None:\n",
    "            legends_offsets = {}\n",
    "        default_legends_offsets = {\n",
    "            2: (-0.2, 0.2),  # Offset for experience 2\n",
    "            3: (-0.2, 0.1),  # Offset for experience 3\n",
    "            4: (-0.2, 0.0),  # Offset for experience 4\n",
    "            5: (-0.2, -0.1),  # Offset for experience 5\n",
    "        }\n",
    "        default_legends_offsets.update(legends_offsets)\n",
    "        legends_offsets = default_legends_offsets\n",
    "    \n",
    "        if arrow_locs is None:\n",
    "            arrow_locs = {}\n",
    "    \n",
    "        plt.xlabel(x_label if x_label is not None else lr.str.porosity)\n",
    "        plt.ylabel(lr.str.cumulative_probability)\n",
    "        plt.title(title if title is not None else f\"{lr.str.cdf_porosity_by_experience}\")\n",
    "        \n",
    "        if remove_y_axis:\n",
    "            plt.gca().tick_params(axis='y', which='both', left=False, labelleft=False)\n",
    "            plt.gca().set_ylabel(\"\")              # Remove axis label\n",
    "            plt.gca().set_yticklabels([])         # Remove tick labels\n",
    "            plt.gca().tick_params(axis='y', length=0)  # Hide tick marks\n",
    "        # Replace legend with floating text annotations\n",
    "        # plt.legend()  # Comment out the traditional legend\n",
    "        \n",
    "        # Add floating text labels with arrows pointing to the best points\n",
    "        for exp in exp_levels:\n",
    "            data = df_work[df_work[\"experience\"] == exp][data_field]\n",
    "            \n",
    "            if len(data) > 0 and exp in colors:\n",
    "                # Find a good point to annotate (e.g., median or a point around 50% CDF)\n",
    "                sorted_data = np.sort(data)\n",
    "                median_idx = int(len(sorted_data) * arrow_locs.get(exp, 0.5))\n",
    "                best_x = sorted_data[median_idx - 1] if len(sorted_data) > 0 else 0\n",
    "                best_y = median_idx / len(sorted_data) if len(sorted_data) > 0 else 0.5\n",
    "                \n",
    "                offset = legends_offsets[exp]\n",
    "                \n",
    "                # Create floating text annotation with arrow\n",
    "                plt.annotate(\n",
    "                    lr.str.experience_level(exp),\n",
    "                    xy=(best_x, best_y),  # Point on the curve to point to\n",
    "                    xytext=(best_x + offset[0], best_y + offset[1]),  # Text position (offset)\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=colors[exp], alpha=0.8, edgecolor='white'),\n",
    "                    arrowprops=dict(\n",
    "                        arrowstyle=\"->\", \n",
    "                        color=colors[exp], \n",
    "                        lw=2,\n",
    "                        connectionstyle=\"arc3,rad=0.2\"  # Curved arrow\n",
    "                    ),\n",
    "                    fontsize=15,\n",
    "                    fontweight='bold',\n",
    "                    color='white'\n",
    "                )\n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim(clip_min_x, extended_max)\n",
    "        plt.ylim(0, 1.05)\n",
    "        \n",
    "        # # Add annotation about the extension\n",
    "        # plt.text(0.98, 0.02, f\"Extended to max + {extension_factor*100:.0f}%\", \n",
    "        #         transform=plt.gca().transAxes, ha='right', va='bottom',\n",
    "        #         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "        #         fontsize=10)\n",
    "\n",
    "def plot_porosity_distribution(df_clicks, data_field=\"porosity\", sz_kind=\"small\", cut_kind=\"full\", \n",
    "                               source_image_key=\"2-SMC-1-AL_72,99m_n=_2,5x_cesc.jpg\",\n",
    "                                       show_extension_lines=True, extension_factor=0.1,\n",
    "                                       extension_style='--', extension_alpha=0.7,\n",
    "                                       exp_levels=None,\n",
    "                                       title=None, x_label=None,\n",
    "                                       clip_min_x=0, plot_width=10, plot_height=6,\n",
    "                                       remove_y_axis=False):\n",
    "    \"\"\"\n",
    "    Plot CDF with extended horizontal lines after reaching 100% probability.\n",
    "    \n",
    "    Parameters:\n",
    "    - show_extension_lines: Whether to show dashed lines extending the CDF\n",
    "    - extension_factor: How much to extend beyond max value (0.1 = 10%)\n",
    "    - extension_style: Line style for extensions ('--', ':', '-', etc.)\n",
    "    - extension_alpha: Transparency of extension lines\n",
    "    \"\"\"\n",
    "    filter = ((df_clicks[\"canceled\"] == False)\n",
    "            & (df_clicks[\"sz_kind\"] == sz_kind)\n",
    "            & (df_clicks[\"cut_kind\"] == cut_kind))\n",
    "    if source_image_key is None:\n",
    "        filter = filter & (df_clicks[\"source_image_key\"].notna())\n",
    "    \n",
    "    df_work = df_clicks[\n",
    "                filter\n",
    "            ]\n",
    "    \n",
    "    name = f\"cdf_{data_field}_by_experience_sz={sz_kind}_cut={cut_kind}_extended\"\n",
    "    print(f\"FILE_NAME = images/{name}.pdf\")\n",
    "    with MyPlot(f\"images/{name}.pdf\", figsize=[plot_width, plot_height]) as mp:\n",
    "\n",
    "        print(f\"sz={sz_kind}\\ncut={cut_kind}\")\n",
    "\n",
    "        # Plot CDF for different experience levels\n",
    "        plt.figure()\n",
    "\n",
    "        # Find the overall maximum value for extending the plot\n",
    "        all_data = df_work[data_field]\n",
    "        global_max = all_data.max() if len(all_data) > 0 else 1.0\n",
    "        extended_max = global_max * (1 + extension_factor)\n",
    "\n",
    "        # Store colors for consistent extension lines\n",
    "        colors = {}\n",
    "        \n",
    "        if exp_levels is None:\n",
    "            exp_levels = [2, 3, 4, 5]\n",
    "\n",
    "        for exp in exp_levels:\n",
    "            data = df_work[df_work[\"experience\"] == exp][data_field]\n",
    "            \n",
    "            if len(data) > 0:\n",
    "                # Plot the main CDF and capture the line object to get its color\n",
    "                line = sns.ecdfplot(data, label=lr.str.experience_level(exp), linewidth=3)\n",
    "                \n",
    "                # Get the color of the last plotted line\n",
    "                color = plt.gca().lines[-1].get_color()\n",
    "                colors[exp] = color\n",
    "                \n",
    "                if show_extension_lines:\n",
    "                    # Get the maximum value for this experience level\n",
    "                    exp_max = data.max()\n",
    "                    \n",
    "                    # Add horizontal extension line\n",
    "                    plt.plot([exp_max, extended_max], [1.0, 1.0], \n",
    "                            color=color, linewidth=3, linestyle=extension_style, \n",
    "                            alpha=extension_alpha)\n",
    "\n",
    "        if global_max > 10000:\n",
    "            def thousands_formatter(x, pos):\n",
    "                return f\"{int(x/1000)}k\"\n",
    "            plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(thousands_formatter))\n",
    "        \n",
    "    \n",
    "        plt.xlabel(x_label if x_label is not None else lr.str.porosity)\n",
    "        plt.ylabel(lr.str.cumulative_probability)\n",
    "        plt.title(title if title is not None else f\"{lr.str.cdf_porosity_by_experience}\")\n",
    "        \n",
    "        if remove_y_axis:\n",
    "            plt.gca().tick_params(axis='y', which='both', left=False, labelleft=False)\n",
    "            plt.gca().set_ylabel(\"\")              # Remove axis label\n",
    "            plt.gca().set_yticklabels([])         # Remove tick labels\n",
    "            plt.gca().tick_params(axis='y', length=0)  # Hide tick marks\n",
    "            \n",
    "        # Replace legend with floating text annotations\n",
    "        plt.legend()  # Comment out the traditional legend\n",
    "        \n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim(clip_min_x, extended_max)\n",
    "        plt.ylim(0, 1.05)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_porosity_distribution_arrows(df_clicks, sz_kind=\"small\", cut_kind=\"full\", exp_levels=[2, 3, 5],\n",
    "                           legends_offsets={2: (-0.12, 0.1), 3: (-0.14, 0.15), 5: (-0.1, 0.1)},\n",
    "                           arrow_locs={2: 0.2, 3:0.4, 5: 0.8},\n",
    "                           extension_factor=0.05, clip_min_x=0.08, plot_width=8)\n",
    "plot_porosity_distribution_arrows(df_clicks, sz_kind=\"big\", cut_kind=\"full\", exp_levels=[2, 3, 5],\n",
    "                           legends_offsets={2: (-0.10, 0.1), 3: (-0.14, 0.15), 5: (-0.1, 0.1)},\n",
    "                           arrow_locs={2: 0.2, 3:0.4, 5: 0.8},\n",
    "                           extension_factor=0.05, clip_min_x=0.1, plot_width=8)\n",
    "plot_porosity_distribution_arrows(df_clicks, sz_kind=\"small\", cut_kind=\"cropped\",\n",
    "                           legends_offsets={2: (-0.18, 0.1), 3: (-0.15, 0.15), 4: (-0.2, -0.05), 5: (-0.02, -0.35)},\n",
    "                           arrow_locs={2: 0.2, 3: 0.4, 4: 0.8, 5: 0.5})\n",
    "plot_porosity_distribution_arrows(df_clicks, sz_kind=\"big\", cut_kind=\"cropped\",\n",
    "                           legends_offsets={2: (-0.16, 0.1), 3: (-0.15, 0.15), 4: (-0.2, -0.05), 5: (-0.02, -0.35)},\n",
    "                           arrow_locs={2: 0.1, 3: 0.4, 4: 0.8, 5: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks[\"pore_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446152a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_porosity_distribution_arrows(df_clicks, data_field=\"pore_count\", sz_kind=\"small\", cut_kind=\"full\", exp_levels=[2, 3, 5],\n",
    "                           legends_offsets={2: (-600, 0.1), 3: (-800, 0.15), 5: (-800, 0.1)},\n",
    "                           arrow_locs={2: 0.4, 5: 0.8},\n",
    "                           title=lr.str.cdf_pore_count_by_experience,\n",
    "                           x_label=lr.str.pore_count,\n",
    "                           clip_min_x=600, extension_factor=0.05, plot_width=7,\n",
    "                           remove_y_axis=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_porosity_distribution_arrows(df_clicks, data_field=\"pore_count\", sz_kind=\"big\", cut_kind=\"full\", exp_levels=[2, 3, 5],\n",
    "                           legends_offsets={2: (-20000, 0.1), 3: (-32000, 0.15), 5: (-40000, 0.1)},\n",
    "                           arrow_locs={2: 0.2, 5: 0.8},\n",
    "                           title=lr.str.cdf_pore_count_by_experience,\n",
    "                           x_label=lr.str.pore_count,\n",
    "                           clip_min_x=20000, extension_factor=0.05, plot_width=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_for_cdf1 = df_clicks[(df_clicks[\"experience\"] == 4)\n",
    "          & (df_clicks[\"canceled\"] == False)\n",
    "          & (df_clicks[\"sz_kind\"] == \"small\")\n",
    "          & (df_clicks[\"cut_kind\"] == \"full\")][\"porosity\"].sort_values()\n",
    "\n",
    "n = len(items_for_cdf1)\n",
    "cdf = np.arange(1, n+1) / n\n",
    "\n",
    "plt.plot(items_for_cdf1, cdf, marker='.', linestyle='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fa841",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_porosity_distribution(\n",
    "    df_clicks, sz_kind=\"small\", cut_kind=\"full\", source_image_key=None,\n",
    "    extension_factor=0.05, clip_min_x=0.0, plot_width=8)\n",
    "plot_porosity_distribution(\n",
    "    df_clicks, sz_kind=\"big\", cut_kind=\"full\", source_image_key=None,\n",
    "    extension_factor=0.05, clip_min_x=0.0, plot_width=8)\n",
    "plot_porosity_distribution(\n",
    "    df_clicks, sz_kind=\"small\", cut_kind=\"cropped\", source_image_key=None,\n",
    "    )\n",
    "plot_porosity_distribution(\n",
    "    df_clicks, sz_kind=\"big\", cut_kind=\"cropped\", source_image_key=None,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_porosity_distribution(df_clicks, data_field=\"pore_count\", sz_kind=\"small\", cut_kind=\"full\",\n",
    "                           title=lr.str.cdf_pore_count_by_experience,\n",
    "                           x_label=lr.str.pore_count,\n",
    "                           clip_min_x=0, extension_factor=0.05, plot_width=7,\n",
    "                           remove_y_axis=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_porosity_distribution(df_clicks, data_field=\"pore_count\", sz_kind=\"big\", cut_kind=\"full\", exp_levels=[2, 3, 5],\n",
    "                           title=lr.str.cdf_pore_count_by_experience,\n",
    "                           x_label=lr.str.pore_count,\n",
    "                           clip_min_x=20000, extension_factor=0.05, plot_width=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "best_color_params_web-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small moldic pore type identification using Encoder Neural Networks\n",
    "\n",
    "In this notebook we will focus on the classification of only small moldic pores in the image.\n",
    "This is relevant because small moldic pores are quite different in shape and its surroundings when compared to large moldic pores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_sal_ii.improc import colorspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting pores from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image_and_save(input_file, output_path, scale_percent):\n",
    "    image_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    output_file = f\"{output_path}/{image_name}_{scale_percent}.jpg\"\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        return\n",
    "\n",
    "    # Reading an image in default mode:\n",
    "    inputImage = cv2.imread(input_file)\n",
    "\n",
    "    # Set the scaling factors\n",
    "    scale_percent = 25  # e.g., downscale to 25%\n",
    "\n",
    "    # Calculate the new dimensions\n",
    "    width = int(inputImage.shape[1] * scale_percent / 100)\n",
    "    height = int(inputImage.shape[0] * scale_percent / 100)\n",
    "    new_dimensions = (width, height)\n",
    "\n",
    "    resized_image = cv2.resize(inputImage, new_dimensions, interpolation=cv2.INTER_AREA)\n",
    "    os.makedirs(f\"{output_path}/\", exist_ok=True)\n",
    "    cv2.imwrite(\n",
    "        output_file,\n",
    "        resized_image,\n",
    "        [cv2.IMWRITE_JPEG_QUALITY, 99]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"ML-tste_original\"\n",
    "path = f\"../data/classificada_01/{image_name}.jpg\"\n",
    "scale_image_and_save(path, \"../out/classificada_01/\", 25)\n",
    "\n",
    "image_name = \"ML-tste_classidicada\"\n",
    "path = f\"../data/classificada_01/{image_name}.jpg\"\n",
    "scale_image_and_save(path, \"../out/classificada_01/\", 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"ML-tste_original\"\n",
    "path = f\"../out/classificada_01/{image_name}_25.jpg\"\n",
    "inputImage = cv2.imread(path)\n",
    "plt.imshow(inputImage[:,:,::-1])\n",
    "\n",
    "# BGR to CMKY:\n",
    "inputImageCMYK = colorspace.bgr2cmyk(inputImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(C, M, Y, K) = (inputImageCMYK[..., 0],\n",
    "                inputImageCMYK[..., 1],\n",
    "                inputImageCMYK[..., 2],\n",
    "                inputImageCMYK[..., 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryImage = cv2.inRange(\n",
    "    inputImageCMYK,\n",
    "    (92,   0,   0,   0),\n",
    "    (255, 255,  64, 196))\n",
    "binaryImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(binaryImage, cmap='gray')\n",
    "cv2.imwrite(\"../out/some_prefilter.jpg\", binaryImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "binaryImage = cv2.morphologyEx(binaryImage, cv2.MORPH_ERODE, kernel, iterations=1)\n",
    "binaryImage = cv2.morphologyEx(binaryImage, cv2.MORPH_DILATE, kernel, iterations=1)\n",
    "binaryImage = cv2.morphologyEx(binaryImage, cv2.MORPH_DILATE, kernel, iterations=1)\n",
    "binaryImage = cv2.morphologyEx(binaryImage, cv2.MORPH_ERODE, kernel, iterations=1)\n",
    "\n",
    "plt.imshow(binaryImage, cmap='gray')\n",
    "cv2.imwrite(\"../out/some.jpg\", binaryImage)\n",
    "porosidade = np.sum(binaryImage/255)/binaryImage.size\n",
    "print(f\"porosidade = {porosidade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "label_img = label(binaryImage)\n",
    "regions = regionprops(label_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objs = []\n",
    "for it, region in enumerate(regions):\n",
    "    ys = (region.coords.T[0] - label_img.shape[0]/2)/(label_img.shape[0]/2)\n",
    "    xs = (region.coords.T[1] - label_img.shape[1]/2)/(label_img.shape[1]/2)\n",
    "    obj = {\n",
    "        \"area\": region.area,\n",
    "        \"max-dist\": max((ys**2 + xs**2)**0.5),\n",
    "    }\n",
    "    all_objs.append(obj)\n",
    "\n",
    "df = pd.DataFrame(all_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = max(df[\"max-dist\"])\n",
    "colored_image3 = np.zeros((*label_img.shape, 3), dtype=np.uint8)\n",
    "for it, region in enumerate(regions):\n",
    "    if df[\"max-dist\"].iloc[it] <= max_dist*0.8:\n",
    "        color_value = np.random.randint(0, 255, size=3)\n",
    "        colored_image3[region.coords.T[0], region.coords.T[1]] = color_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(colored_image3)\n",
    "cv2.imwrite(\"../out/colored_regions_rem_dist.jpg\", colored_image3[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.area.hist(bins=1000)\n",
    "ax.set_xlim([0, 25000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = max(df[\"max-dist\"])\n",
    "colored_image3 = np.zeros((*label_img.shape, 3), dtype=np.uint8)\n",
    "for it, region in enumerate(regions):\n",
    "    if df[\"max-dist\"].iloc[it] <= max_dist*0.8 and df[\"area\"].iloc[it] <= 8000:\n",
    "        color_value = np.random.randint(0, 255, size=3)\n",
    "        colored_image3[region.coords.T[0], region.coords.T[1]] = color_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(colored_image3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = max(df[\"max-dist\"])\n",
    "pores_image3 = np.zeros(label_img.shape, dtype=np.uint8)\n",
    "for it, region in enumerate(regions):\n",
    "    if df[\"max-dist\"].iloc[it] <= max_dist*0.8 and df[\"area\"].iloc[it] <= 8000:\n",
    "        color_value = 255\n",
    "        pores_image3[region.coords.T[0], region.coords.T[1]] = color_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pores_image3.shape)\n",
    "plt.imshow(pores_image3, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading categorized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"ML-tste_classidicada\"\n",
    "path = f\"../out/classificada_01/{image_name}_25.jpg\"\n",
    "inputImage_cl = cv2.imread(path)\n",
    "plt.imshow(inputImage_cl[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryImage_clRed = cv2.inRange(\n",
    "    inputImage_cl,\n",
    "    #  B,   G,   R\n",
    "    (  0,   0, 240),\n",
    "    (  5,   5, 255))\n",
    "plt.imshow(binaryImage_clRed, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"../out/binaryImage_clRed.jpg\", binaryImage_clRed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "image_pred_true = np.zeros([*binaryImage_clRed.shape, 3], dtype=np.uint8)\n",
    "image_pred_true = torch.tensor(image_pred_true, dtype=torch.uint8).permute(2, 0, 1)\n",
    "image_pred_true[2,:,:] = torch.tensor(binaryImage_clRed, dtype=torch.uint8)\n",
    "image_pred_true[0,:,:] = torch.tensor(pores_image3, dtype=torch.uint8)\n",
    "image_pred_true = image_pred_true.permute(1, 2, 0)\n",
    "image_pred_true = image_pred_true.numpy()\n",
    "plt.imshow(image_pred_true[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "label_img = label(binaryImage_clRed)\n",
    "regions = regionprops(label_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objs = []\n",
    "for it, region in enumerate(regions):\n",
    "    ys = (region.coords.T[0] - label_img.shape[0]/2)/(label_img.shape[0]/2)\n",
    "    xs = (region.coords.T[1] - label_img.shape[1]/2)/(label_img.shape[1]/2)\n",
    "    obj = {\n",
    "        \"area\": region.area,\n",
    "        \"max-dist\": max((ys**2 + xs**2)**0.5),\n",
    "    }\n",
    "    all_objs.append(obj)\n",
    "\n",
    "df = pd.DataFrame(all_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = max(df[\"max-dist\"])\n",
    "pores_image_clRed_2 = np.zeros(label_img.shape, dtype=np.uint8)\n",
    "for it, region in enumerate(regions):\n",
    "    if df[\"max-dist\"].iloc[it] <= max_dist*0.8 and df[\"area\"].iloc[it] <= 8000:\n",
    "        color_value = 255\n",
    "        pores_image_clRed_2[region.coords.T[0], region.coords.T[1]] = color_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pores_image_clRed_2.shape)\n",
    "plt.imshow(pores_image_clRed_2, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_sal_ii.models.WhitePixelRegionDataset import WhitePixelRegionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "num_samples = 10000\n",
    "dataset = WhitePixelRegionDataset(\n",
    "    pores_image3, inputImage, binaryImage_clRed, num_samples=num_samples)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(data_loader)\n",
    "data = next(dataiter)\n",
    "(img, imgTarget, centerPixel) = data\n",
    "print(data)\n",
    "print(len(data))\n",
    "print(torch.min(img), torch.max(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "for data in data_loader:\n",
    "    for it, (img, imgTarget) in enumerate(zip(data[0], data[1])):\n",
    "        if it >= 10: break\n",
    "        img = img/255\n",
    "        imgTarget = imgTarget/255\n",
    "        # print(img.numpy().shape, img.dtype)\n",
    "        axes[it//5*2+0, it%5].imshow(img.numpy()[:,:,::-1])\n",
    "        axes[it//5*2+1, it%5].imshow(imgTarget.numpy(), cmap=\"gray\", vmin=0, vmax=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from pre_sal_ii.models.EncoderNN import EncoderNN\n",
    "\n",
    "model = EncoderNN().to(device)\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=1e-4,\n",
    "                        # weight_decay=1e-3,\n",
    "                       )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_state = None\n",
    "best_model_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 100\n",
    "bar = tqdm(total=num_epochs*num_samples)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data in data_loader:\n",
    "        imgs = data[0].to(device)\n",
    "        imgs = imgs.permute(0, 3, 1, 2)\n",
    "        # print(f\"imgs.shape={imgs.shape}\")\n",
    "        imgs = imgs/255\n",
    "        imgs = F.interpolate(\n",
    "            imgs, size=(32, 32), mode='bilinear',\n",
    "            align_corners=False)\n",
    "        imgs = imgs.reshape(-1, 3*32*32)\n",
    "        # print(f\"imgs.shape={imgs.shape}\")\n",
    "        # break\n",
    "        outputs = model(imgs)\n",
    "        expected = data[1].to(device)/255\n",
    "        expected = torch.squeeze(expected, 2)\n",
    "        # print(expected)\n",
    "        # print(f\"outputs.shape={outputs.shape}\")\n",
    "        # print(f\"expected.shape={expected.shape}\")\n",
    "        # break\n",
    "        loss = criterion(outputs, expected)\n",
    "        \n",
    "        if best_model_state is None or loss.item() < best_model_loss:\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_model_loss = loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        bar.update(32)\n",
    "\n",
    "    print(f\"epoch={epoch}, loss={loss.item():.4f}\")\n",
    "\n",
    "# model = SimpleCNN().to(device)\n",
    "# model.load_state_dict(best_model_state)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_state, \"../models/supervised-2-small-pores.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = EncoderNN().to(device)\n",
    "model2.load_state_dict(best_model_state)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = WhitePixelRegionDataset(\n",
    "    pores_image3, inputImage, binaryImage_clRed, num_samples=-1, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image = np.zeros(binaryImage_clRed.shape, dtype=np.uint8)\n",
    "\n",
    "count_gt_half = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for it, (imgX, _, coords) in enumerate(tqdm(dataset2)):\n",
    "        # print(f\"coords.shape={coords.shape}\")\n",
    "        imgX = imgX.to(device)\n",
    "        imgX = imgX.unsqueeze(0)\n",
    "        imgX = imgX.permute(0, 3, 1, 2)\n",
    "        # print(f\"imgX.shape={imgX.shape}\")\n",
    "        imgX = imgX/255\n",
    "        imgX = F.interpolate(\n",
    "            imgX, size=(32, 32), mode='bilinear',\n",
    "            align_corners=False)\n",
    "        imgX = imgX.reshape(-1, 3*32*32)\n",
    "        # print(f\"imgX.shape={imgX.shape}\")\n",
    "        # break\n",
    "        Y = model(imgX)\n",
    "\n",
    "        pred_image[int(coords[0]), int(coords[1])] = float(Y[0,0])*255\n",
    "\n",
    "        # if float(Y[0,0]) > 0.5:\n",
    "        #     count_gt_half += 1\n",
    "        #     print(f\"{[coords[0], coords[1]]} -> {pred_image[coords[0], coords[1]]} (Y[0,0]={Y[0,0]})\")\n",
    "            \n",
    "        # if it > 1000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_image, vmin=0, vmax=255, cmap=\"gray\")\n",
    "cv2.imwrite(\"../out/sup_pred_2_small_pores_model.jpg\", pred_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred_true = np.zeros([*binaryImage_clRed.shape, 3], dtype=np.uint8)\n",
    "image_pred_true = torch.tensor(image_pred_true, dtype=torch.uint8).permute(2, 0, 1)\n",
    "image_pred_true[0,:,:] = torch.tensor(pores_image3, dtype=torch.uint8)\n",
    "image_pred_true[1,:,:] = torch.tensor(pores_image_clRed_2, dtype=torch.uint8)\n",
    "image_pred_true[2,:,:] = torch.tensor(pred_image, dtype=torch.uint8)\n",
    "image_pred_true = image_pred_true.permute(1, 2, 0)\n",
    "image_pred_true = image_pred_true.numpy()\n",
    "plt.imshow(image_pred_true[:,:,::-1])\n",
    "cv2.imwrite(\"../out/image_pred_true_small_pores_model.jpg\", image_pred_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pre-sal-ii-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

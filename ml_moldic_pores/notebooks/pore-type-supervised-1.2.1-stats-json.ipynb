{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ba9cea",
   "metadata": {},
   "source": [
    "# Pore type prediction from thin-section images 1.2\n",
    "\n",
    "In this notebook, we continue to the analysis of the models trained in the 1.2.0 notebook.\n",
    "\n",
    "For this analysis, we take a mask of the pores that we want to analyse. The mask will consider:\n",
    "- all sizes of pores toghether\n",
    "- different sizes of pores\n",
    "\n",
    "From the different sizes of pores, we will create distributions over the sizes of the extracted information.\n",
    "The info to be extracted is:\n",
    "- positive pixels (50% threshold)\n",
    "- negative pixels (50% threshold)\n",
    "- positive pixels (90% threshold)\n",
    "- negative pixels (90% threshold)\n",
    "- true pixels\n",
    "- false pixels\n",
    "- summed positive pixels\n",
    "- summed negative pixels\n",
    "- true positive pixels (50% threshold)\n",
    "- false positive pixels (50% threshold)\n",
    "- false negative pixels (50% threshold)\n",
    "- true negative pixels (50% threshold)\n",
    "- true positive pixels (90% threshold)\n",
    "- false positive pixels (90% threshold)\n",
    "- false negative pixels (90% threshold)\n",
    "- true negative pixels (90% threshold)\n",
    "- summed true positive pixels\n",
    "- summed false positive pixels\n",
    "- summed true negative pixels\n",
    "- summed false negative pixels\n",
    "- pores with one 50% pixel\n",
    "- pores without one 50% pixel\n",
    "- pores with 25% of 50% pixels\n",
    "- pores without 25% of 50% pixels\n",
    "- pores with majority 50% pixels\n",
    "- pores without majority 50% pixels\n",
    "- pores with one 90% pixel\n",
    "- pores without one 90% pixel\n",
    "- pores with 25% of 90% pixels\n",
    "- pores without 25% of 90% pixels\n",
    "- pores with majority 90% pixels\n",
    "- pores without majority 90% pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d479817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import pre_sal_ii.models as models\n",
    "reload(models)\n",
    "import pre_sal_ii.custom.module1 as m1\n",
    "reload(m1)\n",
    "models.set_all_seeds(0)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from importlib import reload\n",
    "import pre_sal_ii.models.nn as nn_models\n",
    "import pre_sal_ii.models.ds as ds_models\n",
    "reload(ds_models)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pre_sal_ii.improc as improc\n",
    "reload(improc)\n",
    "\n",
    "from typing import cast\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "\n",
    "import pre_sal_ii\n",
    "from tqdm.notebook import tqdm\n",
    "pre_sal_ii.progress = tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def match_group(regex, string, default=None, convert=str):\n",
    "    m = re.search(regex, string)\n",
    "    if m is None:\n",
    "        return default\n",
    "    return convert(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53096584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pred_true(pred, true, mean=None, std=None):\n",
    "    import torch\n",
    "    image_pred_true = np.zeros([*true.shape, 3], dtype=np.uint8)\n",
    "    image_pred_true = torch.tensor(image_pred_true, dtype=torch.uint8).permute(2, 0, 1)\n",
    "    if mean is not None:\n",
    "        image_pred_true[0,:,:] = torch.tensor(mean, dtype=torch.uint8)\n",
    "    elif std is not None:\n",
    "        image_pred_true[0,:,:] = torch.tensor(std, dtype=torch.uint8)\n",
    "    image_pred_true[1,:,:] = torch.tensor(true, dtype=torch.uint8)\n",
    "    image_pred_true[2,:,:] = torch.tensor(pred, dtype=torch.uint8)\n",
    "    image_pred_true = image_pred_true.permute(1, 2, 0)\n",
    "    image_pred_true = image_pred_true.numpy()\n",
    "    return image_pred_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_args(\n",
    "            selector_power=0.0, use_channels=False,\n",
    "            stdev_channel_power=0.0,\n",
    "            mean_channel_weight=1.0,\n",
    "            stdev_channel_weight=1.0,\n",
    "            color_channels_weight=1.0,\n",
    "            normalize_stdev=True,\n",
    "        ):\n",
    "    args = f\"_selector_pwr={selector_power:.2f}\"\n",
    "    if use_channels:\n",
    "        args += f\"_channels_pwr={stdev_channel_power:.2f}\"\n",
    "    else:\n",
    "        args += f\"_channels=False\"\n",
    "    if color_channels_weight != 1.0:\n",
    "        args += f\"_color_wt={color_channels_weight:.2f}\"\n",
    "    if mean_channel_weight != 1.0:\n",
    "        args += f\"_mean_wt={mean_channel_weight:.2f}\"\n",
    "    if stdev_channel_weight != 1.0:\n",
    "        args += f\"_stdev_wt={stdev_channel_weight:.2f}\"\n",
    "    if not normalize_stdev:\n",
    "        args += f\"_stdev_norm=False\"\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d32633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting input images...\")\n",
    "inputImage, inputImage_no_gamma = m1.get_input_image()\n",
    "pores_image3 = m1.get_probability_maps_simple(inputImage)\n",
    "binaryImage_clRed = m1.load_manually_categorized_image()\n",
    "cond = pores_image3 == 1.0\n",
    "\n",
    "print(f\"max(cond.flatten())={max(cond.flatten())}\")\n",
    "plt.imshow(cond)\n",
    "plt.show()\n",
    "\n",
    "mean_image, stdev_image = None, None\n",
    "def get_mean_stdev():\n",
    "    global mean_image, stdev_image\n",
    "    if mean_image is None or stdev_image is None:\n",
    "        mean_image, stdev_image = m1.get_mean_stdev(inputImage_no_gamma)\n",
    "    return mean_image, stdev_image\n",
    "\n",
    "def open_image_and_split(file):\n",
    "    img = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image file: {file}\")\n",
    "\n",
    "    # OpenCV loads images in BGR order\n",
    "    blue, green, red = cv2.split(img)\n",
    "\n",
    "    return green, red\n",
    "\n",
    "def run_images_with_best_models(model_file, debug=False, show_images=False):\n",
    "    import torch\n",
    "    if debug: print(\"Starting run...\")\n",
    "    fold_count = 8\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    selector_power = match_group(r\"_selector_pwr=([0-9]+\\.[0-9]+)\", model_file, 0.0, float)\n",
    "    use_channels = match_group(r\"_channels=(False|True)\", model_file, True, lambda x: x == \"True\")\n",
    "    stdev_channel_power = match_group(r\"_channels_pwr=([0-9]+\\.[0-9]+)\", model_file, 0.0, float)\n",
    "    mean_channel_weight = match_group(r\"_mean_wt=([0-9]+\\.[0-9]+)\", model_file, 1.0, float)\n",
    "    stdev_channel_weight = match_group(r\"_stdev_wt=([0-9]+\\.[0-9]+)\", model_file, 1.0, float)\n",
    "    color_channels_weight = match_group(r\"_color_wt=([0-9]+\\.[0-9]+)\", model_file, 1.0, float)\n",
    "    normalize_stdev = match_group(r\"_stdev_norm=(False|True)\", model_file, True, lambda x: x == \"True\")\n",
    "\n",
    "    args = f\"_selector_pwr={selector_power:.2f}\"\n",
    "    if use_channels:\n",
    "        args += f\"_channels_pwr={stdev_channel_power:.2f}\"\n",
    "    else:\n",
    "        args += f\"_channels=False\"\n",
    "    if color_channels_weight != 1.0:\n",
    "        args += f\"_color_wt={color_channels_weight:.2f}\"\n",
    "    if mean_channel_weight != 1.0:\n",
    "        args += f\"_mean_wt={mean_channel_weight:.2f}\"\n",
    "    if stdev_channel_weight != 1.0:\n",
    "        args += f\"_stdev_wt={stdev_channel_weight:.2f}\"\n",
    "    if not normalize_stdev:\n",
    "        args += f\"_stdev_norm=False\"\n",
    "\n",
    "    if os.path.exists(f\"../out/with_pwr/image_pred_8fold_true1.2{args}.png\"):\n",
    "        gt, pred = open_image_and_split(f\"../out/with_pwr/image_pred_8fold_true1.2{args}.png\")\n",
    "        mean_image2, stdev_image2 = get_mean_stdev()\n",
    "        return binaryImage_clRed, pred, mean_image2, stdev_image2\n",
    "\n",
    "    channels = 3 if not use_channels else 5\n",
    "    models2 = [nn_models.EncoderNN(initial_dim=channels*32*32).to(device) for _ in range(fold_count)]\n",
    "    checkpoint = torch.load(model_file)\n",
    "    for i, m in enumerate(models2):\n",
    "        m.load_state_dict(checkpoint[\"models\"][i])\n",
    "    fold_losses2 = checkpoint[\"fold_losses\"]\n",
    "    \n",
    "    model = models2[np.argmin(fold_losses2)]\n",
    "\n",
    "    if debug: print(\"Adjusting input image...\")\n",
    "    inputImage2 = inputImage.astype(np.float32)/255.\n",
    "    mean_image2, stdev_image2 = None, None\n",
    "    if use_channels:\n",
    "        mean_image2, stdev_image2 = get_mean_stdev()\n",
    "        stdev_image2 = stdev_image2 / max(stdev_image2.flatten())\n",
    "        inputImage2 = inputImage2.astype(np.float32)/255.\n",
    "        inputImage2 = np.dstack((inputImage2, mean_image2, stdev_image2)) # pyright: ignore[reportPossiblyUnboundVariable]\n",
    "\n",
    "    if debug: print(\"Creating dataset...\")\n",
    "    dataset2 = ds_models.WhitePixelRegionDataset(\n",
    "        pores_image3, inputImage2, binaryImage_clRed/255.,\n",
    "        num_samples=-1, seed=None, use_img_to_tensor=True)\n",
    "    dataloader2 = DataLoader(dataset2, batch_size=1024, shuffle=False)\n",
    "\n",
    "    trainer_best = m1.MyTrainer101x101to32x32(model, None, None, device=device, channels=channels)\n",
    "\n",
    "    if debug: print(\"Inferring...\")\n",
    "    pred_image = np.zeros_like(binaryImage_clRed, dtype=np.uint8)\n",
    "\n",
    "    count_gt_half = 0\n",
    "\n",
    "    from pre_sal_ii import progress\n",
    "    with torch.no_grad():\n",
    "        for it, inputs in enumerate(progress(dataloader2)):\n",
    "            _, _, coords = inputs\n",
    "            step, outputs = trainer_best.train_epoch_step(inputs)\n",
    "            Y = outputs\n",
    "\n",
    "            xs = coords[:,1].cpu().numpy()\n",
    "            ys = coords[:,0].cpu().numpy()\n",
    "            vs = Y[:,0].cpu().numpy()\n",
    "            pred_image[ys, xs] = vs*255\n",
    "\n",
    "    if debug: print(\"Creating images...\")\n",
    "    # if show_images:\n",
    "    #     plt.imshow(pred_image, vmin=0, vmax=255, cmap=\"gray\")\n",
    "    #     plt.show()\n",
    "    # os.makedirs(\"../out/with_pwr/\", exist_ok=True)\n",
    "    # cv2.imwrite(f\"../out/with_pwr/sup_pred_8fold_1.2{args}.png\", pred_image)\n",
    "    image_pred_true = combine_pred_true(pred_image, binaryImage_clRed)\n",
    "    if show_images:\n",
    "        plt.imshow(image_pred_true[:,:,::-1])\n",
    "        plt.show()\n",
    "    os.makedirs(\"../out/with_pwr/\", exist_ok=True)\n",
    "    cv2.imwrite(f\"../out/with_pwr/image_pred_8fold_true1.2{args}.png\", image_pred_true)\n",
    "\n",
    "    return binaryImage_clRed, pred_image, mean_image2, stdev_image2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import distance_transform_edt, label\n",
    "\n",
    "\n",
    "def open_but_keep_small_objects(mask, thickness):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (thickness, thickness))\n",
    "    opened = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    dist = distance_transform_edt(mask)\n",
    "\n",
    "    labeled_mask, n_labels = label(mask)\n",
    "    regions = regionprops(labeled_mask)\n",
    "    \n",
    "    for r in regions:\n",
    "        coords = tuple(r.coords.T)\n",
    "        max_radius = dist[coords].max()\n",
    "        diam = 2 * max_radius\n",
    "        \n",
    "        if diam < thickness:\n",
    "            opened[coords] = 255\n",
    "\n",
    "    return opened\n",
    "\n",
    "def thickness_based_components_fast(mask, thicknesses):\n",
    "    \"\"\"\n",
    "    mask: binary mask of pores (uint8 0/1)\n",
    "    thickness: minimum thickness to preserve connections\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Opening\n",
    "    opened = mask\n",
    "    for thickness in thicknesses:\n",
    "        opened = open_but_keep_small_objects(opened, thickness)\n",
    "\n",
    "    # 2. Label seeds (fast)\n",
    "    seeds, n_labels = label(opened)\n",
    "\n",
    "    # Convert seeds to 32-bit for watershed\n",
    "    markers = seeds.astype(np.int32)\n",
    "\n",
    "    # 4. Fast reconstruction via watershed\n",
    "    labels = cv2.watershed(\n",
    "        cv2.cvtColor(mask * 255, cv2.COLOR_GRAY2BGR),  # dummy image\n",
    "        markers\n",
    "    )\n",
    "\n",
    "    # Watershed gives -1 on boundaries â†’ fix\n",
    "    labels[labels < 0] = 0\n",
    "\n",
    "    return labels, n_labels\n",
    "\n",
    "def merge_ground_truth_labels(labels, gt):\n",
    "    labels = labels.copy()\n",
    "    \n",
    "    regions = regionprops(labels)\n",
    "\n",
    "    max_label = labels.max()\n",
    "    w = labels.shape[1]\n",
    "    h = labels.shape[0]\n",
    "    max_dist = 0\n",
    "\n",
    "    for r in regions:\n",
    "        coords = r.coords\n",
    "        gt_values = gt[coords[:, 0], coords[:, 1]]\n",
    "        area_proportion = np.sum(gt_values > 0) / len(gt_values)\n",
    "        if area_proportion >= 0.5:\n",
    "            # remove this label\n",
    "            labels[coords[:, 0], coords[:, 1]] = 0\n",
    "        if r.area < 100:\n",
    "            # remove small objects\n",
    "            labels[coords[:, 0], coords[:, 1]] = 0\n",
    "        ys = (coords.T[0] - h/2)/(h/2)\n",
    "        xs = (coords.T[1] - w/2)/(w/2)\n",
    "        max_dist = max(max_dist, max((xs**2 + ys**2)**0.5))\n",
    "\n",
    "    # relabel using gt\n",
    "    labeled_gt, n_gt_labels = label(gt)\n",
    "    regions = regionprops(labeled_gt)\n",
    "    \n",
    "    for r in regions:\n",
    "        coords = r.coords\n",
    "        ys = (coords.T[0] - h/2)/(h/2)\n",
    "        xs = (coords.T[1] - w/2)/(w/2)\n",
    "        if r.area < 16:\n",
    "            continue\n",
    "        if any((xs**2 + ys**2)**0.5 >= max_dist):\n",
    "            continue\n",
    "        max_label += 1\n",
    "        labels[coords[:, 0], coords[:, 1]] = max_label\n",
    "    \n",
    "    return labels, max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f498761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gt, pred, mean, std = run_images_with_best_models(\"../models/supervised-8-folds-1.2_selector_pwr=1.00_channels_pwr=0.00.pt\")\n",
    "#gt, pred, mean, std = run_images_with_best_models(\"../models/supervised-8-folds-1.2_selector_pwr=1.00_channels=False.pt\")\n",
    "gt, pred, mean, std = run_images_with_best_models(\"../models/supervised-8-folds-1.2_selector_pwr=0.00_channels_pwr=0.00_mean_wt=255.00.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a9ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(gt.flatten()), max(pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd10783",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.zeros([50,50], dtype=np.uint8)\n",
    "test_image[10:11,9:15] = 255\n",
    "test_image[30:45,30:45] = 255\n",
    "test_image[10:25,30:45] = 255\n",
    "plt.imshow(cv2.morphologyEx(test_image, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))))\n",
    "plt.show()\n",
    "plt.imshow(open_but_keep_small_objects(test_image, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_colors(labels):\n",
    "    # labels: 2D array of ints (0..N)\n",
    "    n_labels = labels.max() + 1\n",
    "\n",
    "    # generate random colors for each label\n",
    "    colors = np.random.rand(n_labels, 3)  # RGB in [0,1]\n",
    "\n",
    "    # ensure background (label 0) is black\n",
    "    colors[0] = [0, 0, 0]\n",
    "\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    cmap = ListedColormap(colors)\n",
    "\n",
    "    plt.imshow(labels, cmap=cmap, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def save_label_image_cv2(labels, filename):\n",
    "    \"\"\"\n",
    "    labels: 2D array of ints (0..N)\n",
    "    filename: path to save, e.g. 'out.png'\n",
    "    \"\"\"\n",
    "    labels = labels.astype(np.int32)\n",
    "    n_labels = labels.max() + 1\n",
    "\n",
    "    # Generate random colors for each label\n",
    "    colors = np.random.randint(0, 255, (n_labels, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Make label 0 = black (often background)\n",
    "    colors[0] = [0, 0, 0]\n",
    "\n",
    "    # Map each pixel: (H, W, 3)\n",
    "    color_img = colors[labels]\n",
    "\n",
    "    # Save BGR for OpenCV\n",
    "    cv2.imwrite(filename, cv2.cvtColor(color_img, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels, n_gt_labels = label(gt > 0)\n",
    "plt.imshow(gt_labels, cmap='nipy_spectral')\n",
    "plt.show()\n",
    "regions_gt = regionprops(gt_labels)\n",
    "min_pore_size = min([r.area for r in regions_gt if r.area > 0])\n",
    "max_pore_size = max([r.area for r in regions_gt if r.area > 0])\n",
    "print(f\"min_pore_size={min_pore_size}\")\n",
    "plt.hist([r.area for r in regions_gt if r.area > 0], bins=50, range=(0, 2000))\n",
    "print(sorted([r.area for r in regions_gt if r.area > 0]))\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "from pre_sal_ii.improc import rescale\n",
    "new_image_of_gt_by_area = np.zeros([gt.shape[0], gt.shape[1], 3], dtype=np.uint8)\n",
    "cmap = plt.get_cmap('viridis')\n",
    "for r in regions_gt:\n",
    "    coords = r.coords\n",
    "    area = r.area\n",
    "    color = cmap(rescale(math.log(area), math.log(min_pore_size), math.log(max_pore_size), 1.0, 1./255))[0:3]\n",
    "    new_image_of_gt_by_area[r.coords[:, 0], r.coords[:, 1], :] = np.array(color) * 255\n",
    "plt.imshow(new_image_of_gt_by_area)\n",
    "plt.show()\n",
    "cv2.imwrite(\"../out/gt_pore_size_visualization.png\", new_image_of_gt_by_area[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cond = thickness_based_components_fast(cond.astype(np.uint8), [30, 40])[0]*cond\n",
    "labels_gt_cond = merge_ground_truth_labels(labels_cond, (binaryImage_clRed > 0).astype(np.uint8))[0]\n",
    "show_random_colors(labels_cond)\n",
    "plt.show()\n",
    "save_label_image_cv2(labels_cond, \"../out/labels_cond.png\")\n",
    "show_random_colors(labels_gt_cond)\n",
    "plt.show()\n",
    "save_label_image_cv2(labels_gt_cond, \"../out/labels_gt_cond.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8766af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cond, n_labels_cond = label(cond.astype(np.uint8))\n",
    "regions_cond = regionprops(label_cond)\n",
    "new_gt = np.zeros_like(gt)\n",
    "for r in regions_cond:\n",
    "    coords = r.coords\n",
    "    gt_values = gt[coords[:, 0], coords[:, 1]]\n",
    "    if np.any(gt_values > 0):\n",
    "        new_gt[coords[:, 0], coords[:, 1]] = 1\n",
    "\n",
    "gt_composite = combine_pred_true(new_gt*255, gt, cond*255)\n",
    "plt.imshow(gt_composite)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputImage2, inputImage_no_gamma = m1.get_input_image()\n",
    "mean_image2, stdev_image2 = m1.get_mean_stdev(inputImage_no_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_mask = improc.preprocess_segments(\n",
    "    mean_image, area_threshold=0.05, morphological_processing={\"grow\": 25})\n",
    "plt.imshow(selector_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image2 = np.clip(mean_image2, 0, 255).astype(np.uint8)\n",
    "pred_true_image = combine_pred_true(pred, gt, mean_image2)\n",
    "plt.imshow(pred_true_image[:,:,::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe16898",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_img, n_labels_img = cast(np.ndarray, label(gt > 0))\n",
    "regions = regionprops(label_img)\n",
    "areas = sorted([int(r.area) for r in regions])\n",
    "\n",
    "print(f\"areas={areas}\")\n",
    "\n",
    "intervals = []\n",
    "prev = 0\n",
    "while True:\n",
    "    pos = int(len(areas)*0.75)\n",
    "    if pos < 10:\n",
    "        intervals.append((prev, float('inf')))\n",
    "        break\n",
    "    mid = areas[pos]\n",
    "    areas = areas[pos + 1:]\n",
    "    intervals.append((prev, mid))\n",
    "    prev = mid\n",
    "\n",
    "print(f\"intervals={intervals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836fb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('viridis')\n",
    "img = np.zeros([*gt.shape, 3], dtype=np.uint8)\n",
    "for r in regions:\n",
    "    area = int(r.area)\n",
    "    for i, (low, high) in enumerate(intervals):\n",
    "        color = cmap((i + 1) / len(intervals))[0:3]\n",
    "        if low < area <= high:\n",
    "            img[r.coords[:, 0], r.coords[:, 1], :] = np.array(color) * 255\n",
    "            break\n",
    "\n",
    "max_label = len(intervals)\n",
    "print(f\"max_label={max_label}\")\n",
    "\n",
    "plt.imshow(img, vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_img, n_labels_img = cast(np.ndarray, label(pred > 0))\n",
    "regions = regionprops(label_img)\n",
    "\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "img = np.zeros([*gt.shape, 3], dtype=np.uint8)\n",
    "for r in regions:\n",
    "    area = int(r.area)\n",
    "    for i, (low, high) in enumerate(intervals):\n",
    "        color = cmap((i + 1) / len(intervals))[0:3]\n",
    "        if low < area <= high:\n",
    "            img[r.coords[:, 0], r.coords[:, 1], :] = (color * (pred[r.coords[:, 0], r.coords[:, 1]] / 255.0)[:, None]) * 255\n",
    "            break\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filters(gt, pred, intervals):\n",
    "\n",
    "    label_img, n_labels_img = label(pred > 0)\n",
    "    regions = regionprops(label_img)\n",
    "\n",
    "    img1 = np.zeros_like(gt, dtype=np.uint8)\n",
    "    for r in regions:\n",
    "        area = int(r.area)\n",
    "        for i, (low, high) in enumerate(intervals):\n",
    "            if low < area <= high:\n",
    "                img1[label_img == r.label] = int(i + 1)\n",
    "                break\n",
    "\n",
    "    label_img, n_labels_img = label(gt > 0)\n",
    "    regions = regionprops(label_img)\n",
    "\n",
    "    img2 = np.zeros_like(gt, dtype=np.uint8)\n",
    "    for r in regions:\n",
    "        area = int(r.area)\n",
    "        for i, (low, high) in enumerate(intervals):\n",
    "            if low < area <= high:\n",
    "                img2[label_img == r.label] = int(i + 1)\n",
    "                break\n",
    "\n",
    "    max_label = max(img1.max(), img2.max())\n",
    "    print(f\"max label={max_label}\")\n",
    "\n",
    "    filter = [\n",
    "        (img1 == 1) | (img2 == 1),\n",
    "        (img1 == 2) | (img2 == 2),\n",
    "        (img1 == 3) | (img2 == 3),\n",
    "        (img1 == 4) | (img2 == 4),\n",
    "        ]\n",
    "    return filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(pores_image3.flatten()))\n",
    "# we multiply by pores_image3 because predictions are only valid where pores are present\n",
    "filter = get_filters(gt*pores_image3, pred*pores_image3, intervals)\n",
    "plt.subplots(1, 4, figsize=(16, 4))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(filter[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [True, False]\n",
    "min(x1) == 0 and max(x1) == 1\n",
    "1 + True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7440528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(gt, pred, cond):\n",
    "    assert1 = min(cond.flatten()) == 0 and max(cond.flatten()) == 1\n",
    "    assert2 = min(gt.flatten()) == 0 and max(gt.flatten()) > 0\n",
    "    # assert3 = min(pred.flatten()) == 0 and max(pred.flatten()) > 0\n",
    "    \n",
    "    if not assert1:\n",
    "        print(\"Error: cond image is not binary!\")\n",
    "        print(f\"min(cond.flatten())={min(cond.flatten())}, max(cond.flatten())={max(cond.flatten())}\")\n",
    "        assert assert1\n",
    "    if not assert2:\n",
    "        print(\"Error: gt image is not binary!\")\n",
    "        print(f\"min(gt.flatten())={min(gt.flatten())}, max(gt.flatten())={max(gt.flatten())}\")\n",
    "        plt.imshow(gt)\n",
    "        plt.show()\n",
    "        assert assert2\n",
    "    # if not assert3:\n",
    "    #     print(\"Error: pred image is not in expected range!\")\n",
    "    #     print(f\"min(pred.flatten())={min(pred.flatten())}, max(pred.flatten())={max(pred.flatten())}\")\n",
    "    #     plt.imshow(pred)\n",
    "    #     plt.show()\n",
    "    #     assert assert3\n",
    "    \n",
    "    cond_eq_1 = cond\n",
    "    gt_gt_0 = (gt > 0)\n",
    "    gt_eq_0 = (gt == 0) & cond_eq_1\n",
    "    pred_leq_127 = (pred <= 127) & cond_eq_1\n",
    "    pred_gt_127 = (pred > 127)\n",
    "    pred_leq_229 = (pred <= 229) & cond_eq_1\n",
    "    pred_gt_229 = (pred > 229)\n",
    "    \n",
    "    positive_50p = int(sum(pred_gt_127.flatten()))\n",
    "    negative_50p = int(sum(pred_leq_127.flatten()))\n",
    "    positive_90p = int(sum(pred_gt_229.flatten()))\n",
    "    negative_90p = int(sum(pred_leq_229.flatten()))\n",
    "\n",
    "    true_pixels = int(sum(gt_gt_0.flatten()))\n",
    "    false_pixels = int(sum(gt_eq_0.flatten()))\n",
    "\n",
    "    summed_positive_pixels = float(sum((pred/255.0).flatten()))\n",
    "    summed_negative_pixels = float(sum(((255 - pred)/255.0*cond).flatten()))\n",
    "    \n",
    "    true_positive_50p = int(sum((gt_gt_0 & pred_gt_127).flatten()))\n",
    "    false_positive_50p = int(sum((gt_gt_0 & pred_leq_127).flatten()))\n",
    "    false_negative_50p = int(sum((gt_eq_0 & pred_gt_127).flatten()))\n",
    "    true_negative_50p = int(sum((gt_eq_0 & pred_leq_127).flatten()))\n",
    "\n",
    "    true_positive_90p = int(sum((gt_gt_0 & pred_gt_229).flatten()))\n",
    "    false_positive_90p = int(sum((gt_gt_0 & pred_leq_229).flatten()))\n",
    "    false_negative_90p = int(sum((gt_eq_0 & pred_gt_229).flatten()))\n",
    "    true_negative_90p = int(sum((gt_eq_0 & pred_leq_229).flatten()))\n",
    "    \n",
    "    summed_true_positives = float(sum((pred/255.0 * gt_gt_0).flatten()))\n",
    "    summed_false_positives = float(sum((pred/255.0 * gt_eq_0).flatten()))\n",
    "    summed_true_negatives = float(sum(((255 - pred)/255.0 * gt_eq_0).flatten()))\n",
    "    summed_false_negatives = float(sum(((255 - pred)/255.0 * gt_gt_0).flatten()))\n",
    "    \n",
    "    label_img, _ = label(cond_eq_1)\n",
    "    regions = regionprops(label_img)\n",
    "\n",
    "    pores_1_50p_tp = 0\n",
    "    pores_1_50p_fp = 0\n",
    "    pores_1_50p_fn = 0\n",
    "    pores_1_50p_tn = 0\n",
    "    \n",
    "    pores_1_90p_tp = 0\n",
    "    pores_1_90p_fp = 0\n",
    "    pores_1_90p_fn = 0\n",
    "    pores_1_90p_tn = 0\n",
    "\n",
    "    pores_25p_50p_tp = 0\n",
    "    pores_25p_50p_fp = 0\n",
    "    pores_25p_50p_fn = 0\n",
    "    pores_25p_50p_tn = 0\n",
    "    \n",
    "    pores_25p_90p_tp = 0\n",
    "    pores_25p_90p_fp = 0\n",
    "    pores_25p_90p_fn = 0\n",
    "    pores_25p_90p_tn = 0\n",
    "\n",
    "    pores_50p_50p_tp = 0\n",
    "    pores_50p_50p_fp = 0\n",
    "    pores_50p_50p_fn = 0\n",
    "    pores_50p_50p_tn = 0\n",
    "    \n",
    "    pores_50p_90p_tp = 0\n",
    "    pores_50p_90p_fp = 0\n",
    "    pores_50p_90p_fn = 0\n",
    "    pores_50p_90p_tn = 0\n",
    "\n",
    "    pores_25p_sum_tp = 0\n",
    "    pores_25p_sum_fp = 0\n",
    "    pores_25p_sum_fn = 0\n",
    "    pores_25p_sum_tn = 0\n",
    "    \n",
    "    pores_50p_sum_tp = 0\n",
    "    pores_50p_sum_fp = 0\n",
    "    pores_50p_sum_fn = 0\n",
    "    pores_50p_sum_tn = 0\n",
    "    \n",
    "    pores_75p_sum_tp = 0\n",
    "    pores_75p_sum_fp = 0\n",
    "    pores_75p_sum_fn = 0\n",
    "    pores_75p_sum_tn = 0\n",
    "\n",
    "    # img_test_1_50p = np.zeros([*gt.shape, 3], dtype=np.uint8)\n",
    "    # img_test_1_50p_gt = np.zeros([*gt.shape, 3], dtype=np.uint8)\n",
    "    # img_test_1_50p_gt[gt > 0, 0] = 255\n",
    "\n",
    "    for region in regions:\n",
    "        region_coords = region.coords\n",
    "        \n",
    "        pred_values = pred[region_coords[:, 0], region_coords[:, 1]]\n",
    "        gt_values = gt[region_coords[:, 0], region_coords[:, 1]]\n",
    "        \n",
    "        is_positive = np.any(pred_values > 127)\n",
    "        is_true = np.any(gt_values > 0)\n",
    "        pores_1_50p_tp += int(is_positive and is_true)\n",
    "        pores_1_50p_fp += int(is_positive and not is_true)\n",
    "        pores_1_50p_fn += int(not is_positive and is_true)\n",
    "        pores_1_50p_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "        # img_test_1_50p[region_coords[:, 0], region_coords[:, 1], 0] = int(is_positive) * 255\n",
    "        # img_test_1_50p[region_coords[:, 0], region_coords[:, 1], 1] = int(is_true) * 255\n",
    "        # img_test_1_50p[region_coords[:, 0], region_coords[:, 1], 2] = int(not is_positive and not is_true) * 255\n",
    "        # img_test_1_50p_gt[region_coords[:, 0], region_coords[:, 1], 1] = int(is_true) * 255\n",
    "        \n",
    "        is_positive = np.any(pred_values > 229)\n",
    "        pores_1_90p_tp += int(is_positive and is_true)\n",
    "        pores_1_90p_fp += int(is_positive and not is_true)\n",
    "        pores_1_90p_fn += int(not is_positive and is_true)\n",
    "        pores_1_90p_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "        is_positive = np.sum(pred_values > 127) >= 0.25 * len(pred_values)\n",
    "        pores_25p_50p_tp += int(is_positive and is_true)\n",
    "        pores_25p_50p_fp += int(is_positive and not is_true)\n",
    "        pores_25p_50p_fn += int(not is_positive and is_true)\n",
    "        pores_25p_50p_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "        is_positive = np.sum(pred_values > 229) >= 0.25 * len(pred_values)\n",
    "        pores_25p_90p_tp += int(is_positive and is_true)\n",
    "        pores_25p_90p_fp += int(is_positive and not is_true)\n",
    "        pores_25p_90p_fn += int(not is_positive and is_true)\n",
    "        pores_25p_90p_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "        is_positive = np.sum(pred_values > 127) >= 0.50 * len(pred_values)\n",
    "        pores_50p_50p_tp += int(is_positive and is_true)\n",
    "        pores_50p_50p_fp += int(is_positive and not is_true)\n",
    "        pores_50p_50p_fn += int(not is_positive and is_true)\n",
    "        pores_50p_50p_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "        is_positive = np.sum(pred_values > 229) >= 0.50 * len(pred_values)\n",
    "        pores_50p_90p_tp += int(is_positive and is_true)\n",
    "        pores_50p_90p_fp += int(is_positive and not is_true)\n",
    "        pores_50p_90p_fn += int(not is_positive and is_true)\n",
    "        pores_50p_90p_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "        is_positive = int(np.sum(pred_values / 255.0) >= 0.25 * len(pred_values))\n",
    "        pores_25p_sum_tp += int(is_positive and is_true)\n",
    "        pores_25p_sum_fp += int(is_positive and not is_true)\n",
    "        pores_25p_sum_fn += int(not is_positive and is_true)\n",
    "        pores_25p_sum_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "        is_positive = int(np.sum(pred_values / 255.0) >= 0.50 * len(pred_values))\n",
    "        pores_50p_sum_tp += int(is_positive and is_true)\n",
    "        pores_50p_sum_fp += int(is_positive and not is_true)\n",
    "        pores_50p_sum_fn += int(not is_positive and is_true)\n",
    "        pores_50p_sum_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "        is_positive = int(np.sum(pred_values / 255.0) >= 0.75 * len(pred_values))\n",
    "        pores_75p_sum_tp += int(is_positive and is_true)\n",
    "        pores_75p_sum_fp += int(is_positive and not is_true)\n",
    "        pores_75p_sum_fn += int(not is_positive and is_true)\n",
    "        pores_75p_sum_tn += int(not is_positive and not is_true)\n",
    "        \n",
    "    # cv2.imwrite(\"../out/img_test_1_50p.png\", img_test_1_50p[:,:,::-1])\n",
    "    # cv2.imwrite(\"../out/img_test_1_50p_gt.png\", img_test_1_50p_gt[:,:,::-1])\n",
    "    # raise Exception(\"stop\")\n",
    "\n",
    "    return {\n",
    "    \"positive_50p\": positive_50p,\n",
    "    \"negative_50p\": negative_50p,\n",
    "    \"positive_90p\": positive_90p,\n",
    "    \"negative_90p\": negative_90p,\n",
    "    \"true_pixels\": true_pixels,\n",
    "    \"false_pixels\": false_pixels,\n",
    "    \"summed_positive_pixels\": summed_positive_pixels,\n",
    "    \"summed_negative_pixels\": summed_negative_pixels,\n",
    "    \n",
    "    \"50p\": {\n",
    "        \"tp\": true_positive_50p,\n",
    "        \"fp\": false_positive_50p,\n",
    "        \"fn\": false_negative_50p,\n",
    "        \"tn\": true_negative_50p,\n",
    "    },\n",
    "    \"90p\": {\n",
    "        \"tp\": true_positive_90p,\n",
    "        \"fp\": false_positive_90p,\n",
    "        \"fn\": false_negative_90p,\n",
    "        \"tn\": true_negative_90p,\n",
    "    },\n",
    "    \"summed\": {\n",
    "        \"tp\": summed_true_positives,\n",
    "        \"fp\": summed_false_positives,\n",
    "        \"tn\": summed_true_negatives,\n",
    "        \"fn\": summed_false_negatives,\n",
    "    },\n",
    "    \n",
    "    \"pores_1_50p\": {\n",
    "        \"tp\": pores_1_50p_tp,\n",
    "        \"fp\": pores_1_50p_fp,\n",
    "        \"fn\": pores_1_50p_fn,\n",
    "        \"tn\": pores_1_50p_tn,\n",
    "    },\n",
    "    \"pores_1_90p\": {\n",
    "        \"tp\": pores_1_90p_tp,\n",
    "        \"fp\": pores_1_90p_fp,\n",
    "        \"fn\": pores_1_90p_fn,\n",
    "        \"tn\": pores_1_90p_tn,\n",
    "    },\n",
    "    \"pores_25p_50p\": {\n",
    "        \"tp\": pores_25p_50p_tp,\n",
    "        \"fp\": pores_25p_50p_fp,\n",
    "        \"fn\": pores_25p_50p_fn,\n",
    "        \"tn\": pores_25p_50p_tn,\n",
    "    },\n",
    "    \"pores_25p_90p\": {\n",
    "        \"tp\": pores_25p_90p_tp,\n",
    "        \"fp\": pores_25p_90p_fp,\n",
    "        \"fn\": pores_25p_90p_fn,\n",
    "        \"tn\": pores_25p_90p_tn,\n",
    "    },\n",
    "    \"pores_50p_50p\": {\n",
    "        \"tp\": pores_50p_50p_tp,\n",
    "        \"fp\": pores_50p_50p_fp,\n",
    "        \"fn\": pores_50p_50p_fn,\n",
    "        \"tn\": pores_50p_50p_tn,\n",
    "    },\n",
    "    \"pores_50p_90p\": {\n",
    "        \"tp\": pores_50p_90p_tp,\n",
    "        \"fp\": pores_50p_90p_fp,\n",
    "        \"fn\": pores_50p_90p_fn,\n",
    "        \"tn\": pores_50p_90p_tn,\n",
    "    },\n",
    "    \"pores_25p_sum\": {\n",
    "        \"tp\": pores_25p_sum_tp,\n",
    "        \"fp\": pores_25p_sum_fp,\n",
    "        \"fn\": pores_25p_sum_fn,\n",
    "        \"tn\": pores_25p_sum_tn,\n",
    "    },\n",
    "    \"pores_50p_sum\": {\n",
    "        \"tp\": pores_50p_sum_tp,\n",
    "        \"fp\": pores_50p_sum_fp,\n",
    "        \"fn\": pores_50p_sum_fn,\n",
    "        \"tn\": pores_50p_sum_tn,\n",
    "    },\n",
    "    \"pores_75p_sum\": {\n",
    "        \"tp\": pores_75p_sum_tp,\n",
    "        \"fp\": pores_75p_sum_fp,\n",
    "        \"fn\": pores_75p_sum_fn,\n",
    "        \"tn\": pores_75p_sum_tn,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055bdb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_label)\n",
    "assert max_label == 4\n",
    "def get_all_stats(gt, pred, cond):\n",
    "    gt = gt*cond\n",
    "    pred = pred*cond\n",
    "    all = get_stats(gt, pred, cond)\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    for grp in range(max_label):\n",
    "        sub_gt = gt * filter[grp]\n",
    "        sub_pred = pred * filter[grp]\n",
    "\n",
    "        group_stats = get_stats(sub_gt, sub_pred, filter[grp])\n",
    "        groups.append(group_stats)\n",
    "        \n",
    "    return {\"all\": all, \"groups\": groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "A = range(11)  # 0 to 10\n",
    "B = range(11)\n",
    "pairs = list(itertools.product(A, B))\n",
    "import pre_sal_ii\n",
    "reload(pre_sal_ii)\n",
    "prev_progress = pre_sal_ii.progress\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "try:\n",
    "    bar = tqdm(pairs)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    for i, j in bar:\n",
    "        args = get_filename_args(i/10, True, j/10)\n",
    "        bar.set_description(args)\n",
    "        gt, pred, mean, std = run_images_with_best_models(f\"../models/supervised-8-folds-1.2{args}.pt\")\n",
    "finally:\n",
    "    pre_sal_ii.progress = prev_progress\n",
    "\n",
    "try:\n",
    "    bar = tqdm(A)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    for i in bar:\n",
    "        args = get_filename_args(i/10, False)\n",
    "        bar.set_description(args)\n",
    "        gt, pred, mean, std = run_images_with_best_models(f\"../models/supervised-8-folds-1.2{args}.pt\")\n",
    "finally:\n",
    "    pre_sal_ii.progress = prev_progress\n",
    "\n",
    "\n",
    "try:\n",
    "    bar = tqdm(pairs)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    for i, j in bar:\n",
    "        args = get_filename_args(i/10, True, j/10, mean_channel_weight=255.0)\n",
    "        bar.set_description(args)\n",
    "        gt, pred, mean, std = run_images_with_best_models(f\"../models/supervised-8-folds-1.2{args}.pt\")\n",
    "finally:\n",
    "    pre_sal_ii.progress = prev_progress\n",
    "\n",
    "try:\n",
    "    bar = tqdm(A)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    for i in bar:\n",
    "        args = get_filename_args(i/10, False, mean_channel_weight=255.0)\n",
    "        bar.set_description(args)\n",
    "        gt, pred, mean, std = run_images_with_best_models(f\"../models/supervised-8-folds-1.2{args}.pt\")\n",
    "finally:\n",
    "    pre_sal_ii.progress = prev_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e99fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from importlib import reload\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def process_image_files():\n",
    "    import pre_sal_ii\n",
    "    reload(pre_sal_ii)\n",
    "    prev_progress = pre_sal_ii.progress\n",
    "\n",
    "    # Find all matching images\n",
    "    files = sorted(glob.glob(\"../out/with_pwr/image_pred_8fold_true1.2*.png\"))\n",
    "\n",
    "    try:\n",
    "        bar = tqdm(files)\n",
    "        pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "\n",
    "        for filepath in bar:\n",
    "            # Extract the \"args\" from the filename\n",
    "            filename = os.path.basename(filepath)\n",
    "            # filename: image_pred_8fold_true1.2{args}.png\n",
    "            args = filename.removeprefix(\"image_pred_8fold_true1.2\").removesuffix(\".png\")\n",
    "\n",
    "            out_file = f\"../out/with_pwr/stats/stats_pred_8fold_1.2{args}.json\"\n",
    "            if os.path.exists(out_file):\n",
    "                continue\n",
    "            \n",
    "            bar.set_description(args)\n",
    "\n",
    "            gt, pred = open_image_and_split(filepath)\n",
    "            data = get_all_stats(gt*cond, pred*cond, cond)\n",
    "\n",
    "            os.makedirs(\"../out/with_pwr/stats/\", exist_ok=True)\n",
    "\n",
    "            with open(out_file, \"w\") as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "\n",
    "    finally:\n",
    "        pre_sal_ii.progress = prev_progress\n",
    "\n",
    "process_image_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930c21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

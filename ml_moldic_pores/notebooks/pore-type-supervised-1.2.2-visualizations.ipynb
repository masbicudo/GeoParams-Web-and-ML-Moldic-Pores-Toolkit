{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71389f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pre_sal_ii.libs.plot_context as pc\n",
    "\n",
    "from importlib import reload\n",
    "import localizable_resources as lr\n",
    "\n",
    "def reload_libs_env():\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\".env\", override=True)\n",
    "\n",
    "    reload(pc)\n",
    "    reload(lr)\n",
    "\n",
    "reload_libs_env()\n",
    "\n",
    "global_sizes = pc.rc_sizes(16, 21, 24, [8, 8])\n",
    "MyPlot = pc.create_plot_context(global_sizes, reload_libs_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f6954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from importlib import reload\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "def match_group(regex, string, default=None, convert=str):\n",
    "    m = re.search(regex, string)\n",
    "    if m is None:\n",
    "        return default\n",
    "    return convert(m.group(1))\n",
    "\n",
    "def add_items(all_data, data, info, type):\n",
    "    all_data.append({**data[\"50p\"], \"type\": type, \"criteria\": \"50p\", **info})\n",
    "    all_data.append({**data[\"90p\"], \"type\": type, \"criteria\": \"90p\", **info})\n",
    "    all_data.append({**data[\"summed\"], \"type\": type, \"criteria\": \"summed\", **info})\n",
    "    all_data.append({**data[\"pores_1_50p\"], \"type\": type, \"criteria\": \"pores_1_50p\", **info})\n",
    "    all_data.append({**data[\"pores_1_90p\"], \"type\": type, \"criteria\": \"pores_1_90p\", **info})\n",
    "    all_data.append({**data[\"pores_25p_50p\"], \"type\": type, \"criteria\": \"pores_25p_50p\", **info})\n",
    "    all_data.append({**data[\"pores_25p_90p\"], \"type\": type, \"criteria\": \"pores_25p_90p\", **info})\n",
    "    all_data.append({**data[\"pores_50p_50p\"], \"type\": type, \"criteria\": \"pores_50p_50p\", **info})\n",
    "    all_data.append({**data[\"pores_50p_90p\"], \"type\": type, \"criteria\": \"pores_50p_90p\", **info})\n",
    "    all_data.append({**data[\"pores_25p_sum\"], \"type\": type, \"criteria\": \"pores_25p_sum\", **info})\n",
    "    all_data.append({**data[\"pores_50p_sum\"], \"type\": type, \"criteria\": \"pores_50p_sum\", **info})\n",
    "    all_data.append({**data[\"pores_75p_sum\"], \"type\": type, \"criteria\": \"pores_75p_sum\", **info})\n",
    "\n",
    "def process_image_files():\n",
    "    import pre_sal_ii\n",
    "    reload(pre_sal_ii)\n",
    "    prev_progress = pre_sal_ii.progress\n",
    "\n",
    "    # Find all matching images\n",
    "    files = sorted(glob.glob(\"../out/with_pwr/stats/stats_pred_8fold_1.2*.json\"))\n",
    "\n",
    "    try:\n",
    "        bar = tqdm(files)\n",
    "        pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "        all_data = []\n",
    "\n",
    "        for filepath in bar:\n",
    "            # Extract the \"args\" from the filename\n",
    "            filename = os.path.basename(filepath)\n",
    "            # filename: image_pred_8fold_true1.2{args}.png\n",
    "            args = filename.removeprefix(\"stats_pred_8fold_1.2\").removesuffix(\".json\")\n",
    "\n",
    "            selector_power = match_group(r\"_selector_pwr=([0-9]+\\.[0-9]+)\", args, 0.0, float)\n",
    "            use_channels = match_group(r\"_channels=(False|True)\", args, True, lambda x: x == \"True\")\n",
    "            stdev_channel_power = match_group(r\"_channels_pwr=([0-9]+\\.[0-9]+)\", args, 0.0, float)\n",
    "            mean_channel_weight = match_group(r\"_mean_wt=([0-9]+\\.[0-9]+)\", args, 1.0, float)\n",
    "            stdev_channel_weight = match_group(r\"_stdev_wt=([0-9]+\\.[0-9]+)\", args, 1.0, float)\n",
    "            color_channels_weight = match_group(r\"_color_wt=([0-9]+\\.[0-9]+)\", args, 1.0, float)\n",
    "            normalize_stdev = match_group(r\"_stdev_norm=(False|True)\", args, True, lambda x: x == \"True\")\n",
    "\n",
    "            info = {\n",
    "                \"selector_power\": selector_power,\n",
    "                \"use_channels\": use_channels,\n",
    "                \"stdev_channel_power\": stdev_channel_power,\n",
    "                \"mean_channel_weight\": mean_channel_weight,\n",
    "                \"stdev_channel_weight\": stdev_channel_weight,\n",
    "                \"color_channels_weight\": color_channels_weight,\n",
    "                \"normalize_stdev\": normalize_stdev,\n",
    "            }\n",
    "\n",
    "            # Load the JSON data\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            add_items(all_data, data[\"all\"], info, \"all\")\n",
    "            add_items(all_data, data[\"groups\"][0], info, \"micro\")\n",
    "            add_items(all_data, data[\"groups\"][1], info, \"small\")\n",
    "            add_items(all_data, data[\"groups\"][2], info, \"medium\")\n",
    "            add_items(all_data, data[\"groups\"][3], info, \"large\")\n",
    "            \n",
    "            \n",
    "        return all_data\n",
    "    finally:\n",
    "        pre_sal_ii.progress = prev_progress\n",
    "\n",
    "all_data = process_image_files()\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518247a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df[\"accuracy\"] = (df.tp + df.tn) / (df.tp + df.fp + df.fn + df.tn)\n",
    "    df[\"precision\"] = df.tp / (df.tp + df.fp)\n",
    "    df[\"recall\"] = df.tp / (df.tp + df.fn)\n",
    "    df[\"f1\"] = 2 * df[\"precision\"] * df[\"recall\"] / (df[\"precision\"] + df[\"recall\"])\n",
    "    df[\"iou\"] = df.tp / (df.tp + df.fp + df.fn)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_metrics(df)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f585d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../out/with_pwr/stats/pore_type_supervised_1.2.2_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3821f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_feature_importances(df):\n",
    "    df_encoded = pd.get_dummies(df, columns=[\"type\", \"criteria\", \"mean_channel_weight\", \"use_channels\"], drop_first=True)\n",
    "    features = df_encoded.drop(columns=[\"tp\",\"fp\",\"fn\",\"tn\",\"f1\",\"accuracy\",\"precision\",\"recall\",\"iou\"])\n",
    "    target = df_encoded[\"f1\"]\n",
    "    tree = DecisionTreeRegressor(max_depth=3)\n",
    "    tree.fit(features, target)\n",
    "    importances = pd.Series(tree.feature_importances_, index=features.columns)\n",
    "    return importances.sort_values(ascending=False)\n",
    "\n",
    "importances_all = get_feature_importances(df)\n",
    "print(importances_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_large = get_feature_importances(df[df.type == \"large\"])\n",
    "print(importances_large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_medium = get_feature_importances(df[df.type == \"medium\"])\n",
    "print(importances_medium)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_small = get_feature_importances(df[df.type == \"small\"])\n",
    "print(importances_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_micro = get_feature_importances(df[df.type == \"micro\"])\n",
    "print(importances_micro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importances = pd.DataFrame({\n",
    "    \"all\": importances_all,\n",
    "    \"large\": importances_large,\n",
    "    \"medium\": importances_medium,\n",
    "    \"small\": importances_small, \n",
    "    \"micro\": importances_micro,\n",
    "})\n",
    "df_importances = df_importances.dropna()\n",
    "df_importances = df_importances[(df_importances != 0).any(axis=1)]\n",
    "df_importances = df_importances.loc[df_importances.mean(axis=1).sort_values(ascending=False).index]\n",
    "print(df_importances.to_latex(\n",
    "        index=True,\n",
    "        caption=\"Feature Importances for Model Performance\",\n",
    "        label=\"tab:feature_importances\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b38e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "crits = [\"90p\", \"summed\", \"pores_1_50p\", \"pores_25p_sum\"]\n",
    "\n",
    "df_best = df[(df[\"mean_channel_weight\"] == 255.0) & (df[\"criteria\"].isin(crits))]\n",
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef00b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"selector_power_vs_f1_boxplot\"\n",
    "with MyPlot(f\"../images/{name}.pdf\", figsize=[10, 6]) as mp:\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    df_best.boxplot(\n",
    "        ax=ax,\n",
    "        column=\"f1\",\n",
    "        by=\"selector_power\",\n",
    "        grid=False,\n",
    "    )\n",
    "    plt.xlabel(\"selector power\")\n",
    "    plt.ylabel(\"F1 score\")\n",
    "    plt.title(\"Effect of selector power on model quality\")\n",
    "    plt.suptitle(\"\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baeb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88328a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    (1, 0, 0),  # red for -1\n",
    "    (1, 1, 1),  # white for 0\n",
    "    (0, 0, 1),  # blue for +1\n",
    "]\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "cmap = LinearSegmentedColormap.from_list(\"red_white_blue\", colors, N=256)\n",
    "\n",
    "\n",
    "# Compute correlation matrix\n",
    "numeric_df = df.select_dtypes(include=[float, int]).drop(columns=[\"stdev_channel_weight\", \"color_channels_weight\"])\n",
    "numeric_df = numeric_df.loc[:, numeric_df.std() > 0]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr = numeric_df.corr()\n",
    "\n",
    "# ---- Hierarchical clustering on the correlation matrix ----\n",
    "# Convert correlation to a distance matrix\n",
    "distance = 1 - corr\n",
    "\n",
    "# Perform clustering\n",
    "link = linkage(distance, method='average')\n",
    "\n",
    "# Get ordering of rows/columns\n",
    "order = leaves_list(link)\n",
    "\n",
    "# Reorder the correlation matrix\n",
    "corr_reordered = corr.values[order][:, order]\n",
    "labels_reordered = corr.columns[order]\n",
    "\n",
    "# ---- Plot heatmap ----\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "cax = ax.imshow(corr_reordered, interpolation='nearest', cmap=cmap, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticks(np.arange(len(labels_reordered)))\n",
    "ax.set_yticks(np.arange(len(labels_reordered)))\n",
    "\n",
    "ax.set_xticklabels(labels_reordered, rotation=90)\n",
    "ax.set_yticklabels(labels_reordered)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad80735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets\n",
    "from pre_sal_ii.libs.plot_context import rc_sizes\n",
    "\n",
    "\n",
    "def violinplot(df):\n",
    "    df_no = df[df[\"use_channels\"] == False]\n",
    "    df_yes = df[df[\"use_channels\"] == True]\n",
    "\n",
    "    metrics = [\"f1\", \"iou\", \"recall\", \"precision\", \"accuracy\"]\n",
    "    metrics_names = [\"F1\", \"IoU\", \"Recall\", \"Precision\", \"Accuracy\"]\n",
    "\n",
    "    # Prepare data in the form:\n",
    "    #   data[metric] = [values_when_no, values_when_yes]\n",
    "    data = {m: [df_no[m].dropna().values, df_yes[m].dropna().values] for m in metrics}\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(metrics), sharey=False)\n",
    "\n",
    "    for i, (metric, metric_name) in enumerate(zip(metrics, metrics_names)):\n",
    "        ax = axes[i]\n",
    "\n",
    "        parts = ax.violinplot(\n",
    "            data[metric],\n",
    "            positions=[1, 2],\n",
    "            showmeans=True,\n",
    "            showextrema=True\n",
    "        )\n",
    "\n",
    "        # Set x-axis\n",
    "        ax.set_xticks([1, 2])\n",
    "        ax.set_xticklabels([\"No user channels\", \"With user channels\"], rotation=60)\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        ax.set_title(metric_name)\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "name = \"user_channels_effect_violinplot\"\n",
    "with MyPlot(f\"../images/{name}.pdf\", figsize=[15, 5], sizes=pc.rc_sizes(12, 14, 16, [8, 8])) as mp:\n",
    "    violinplot(df)\n",
    "\n",
    "types = df[\"type\"].unique()\n",
    "for type in types:\n",
    "    df_type = df[df[\"type\"] == type]\n",
    "    name = f\"user_channels_effect_violinplot_{type}\"\n",
    "    with MyPlot(f\"../images/{name}.pdf\", figsize=[15, 5], sizes=pc.rc_sizes(12, 14, 16, [8, 8])) as mp:\n",
    "        violinplot(df_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735b9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fd7735",
   "metadata": {},
   "source": [
    "# Pore type prediction from thin-section images 1.1\n",
    "\n",
    "In this notebook, we get all the code from the 1.0 version, and execute it  many times with multiple parameters combinations.\n",
    "\n",
    "The parameter groups are:\n",
    "- use data $C_{min}{\\times}K_{max}$ as input selector: yes/no\n",
    "- use data $C_{min}{\\times}K_{max}$ as input channels: yes/no\n",
    "\n",
    "The combinations in this case yield 4 different instances of trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_sal_ii.improc import colorspace\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "from pre_sal_ii.improc import scale_image_and_save, adjust_gamma\n",
    "\n",
    "import pre_sal_ii.models as models\n",
    "reload(models)\n",
    "models.set_all_seeds(0)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from pre_sal_ii.training.image_clustering import cluster_pixels_kmeans_constrained_model\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from pre_sal_ii.improc import generate_region_map_from_centroids\n",
    "from skimage.measure import label, regionprops\n",
    "from typing import cast\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from pre_sal_ii.training import Trainer\n",
    "import torch\n",
    "\n",
    "\n",
    "import pre_sal_ii.models.features.data_models as data_models\n",
    "\n",
    "from importlib import reload\n",
    "import pre_sal_ii.models.nn as nn_models\n",
    "import pre_sal_ii.models.ds as ds_models\n",
    "reload(ds_models)\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pre_sal_ii.training import Trainer\n",
    "\n",
    "import pre_sal_ii.models as md\n",
    "\n",
    "from pre_sal_ii import improc\n",
    "reload(improc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b20e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_image():\n",
    "    \n",
    "    image_name = \"ML-tste_original\"\n",
    "    path = f\"../out/classificada_01/{image_name}_25.jpg\"\n",
    "    inputImage_no_gamma: np.ndarray = cv2.imread(path)\n",
    "    inputImage = adjust_gamma(inputImage_no_gamma, 0.5)\n",
    "    \n",
    "    return inputImage, inputImage_no_gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e9c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_maps_simple(inputImage):\n",
    "\n",
    "    # BGR to CMKY:\n",
    "    inputImageCMYK = colorspace.bgr2cmyk(inputImage)\n",
    "\n",
    "    binaryImage = cv2.inRange(\n",
    "        inputImageCMYK,\n",
    "        (92,   0,   0,   0),\n",
    "        (255, 255,  64, 196))\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "    binaryImage = cv2.morphologyEx(binaryImage, cv2.MORPH_ERODE, kernel, iterations=1)\n",
    "    binaryImage = cv2.morphologyEx(binaryImage, cv2.MORPH_DILATE, kernel, iterations=1)\n",
    "    binaryImage = cv2.morphologyEx(binaryImage, cv2.MORPH_DILATE, kernel, iterations=1)\n",
    "    binaryImage = cv2.morphologyEx(binaryImage, cv2.MORPH_ERODE, kernel, iterations=1)\n",
    "\n",
    "    label_img = cast(np.ndarray, label(binaryImage))\n",
    "    regions = regionprops(label_img)\n",
    "\n",
    "    all_objs = []\n",
    "    for it, region in enumerate(regions):\n",
    "        ys = (region.coords.T[0] - label_img.shape[0]/2)/(label_img.shape[0]/2)\n",
    "        xs = (region.coords.T[1] - label_img.shape[1]/2)/(label_img.shape[1]/2)\n",
    "        obj = {\n",
    "            \"area\": region.area,\n",
    "            \"max-dist\": max((ys**2 + xs**2)**0.5),\n",
    "        }\n",
    "        all_objs.append(obj)\n",
    "\n",
    "    df = pd.DataFrame(all_objs)\n",
    "\n",
    "    max_dist = max(df[\"max-dist\"])\n",
    "    pores_image3 = np.zeros(label_img.shape, dtype=np.uint8)\n",
    "    for it, region in enumerate(regions):\n",
    "        if df[\"max-dist\"].iloc[it] <= max_dist*0.8:\n",
    "            color_value = 255\n",
    "            pores_image3[region.coords.T[0], region.coords.T[1]] = color_value\n",
    "\n",
    "    return pores_image3/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_manually_categorized_image():\n",
    "    image_name = \"ML-tste_classidicada\"\n",
    "    path = f\"../out/classificada_01/{image_name}_25.jpg\"\n",
    "    inputImage_cl = cv2.imread(path)\n",
    "    binaryImage_clRed: np.ndarray = cv2.inRange(\n",
    "        inputImage_cl,\n",
    "        #  B,   G,   R\n",
    "        (  0,   0, 240),\n",
    "        (  5,   5, 255))\n",
    "    return binaryImage_clRed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8b0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_central_objects(image: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    label_img = label(image)\n",
    "    regions = regionprops(label_img)\n",
    "\n",
    "    all_objs = []\n",
    "    for it, region in enumerate(regions):\n",
    "        ys = (region.coords.T[0] - label_img.shape[0]/2)/(label_img.shape[0]/2)\n",
    "        xs = (region.coords.T[1] - label_img.shape[1]/2)/(label_img.shape[1]/2)\n",
    "        obj = {\n",
    "            \"area\": region.area,\n",
    "            \"max-dist\": max((ys**2 + xs**2)**0.5),\n",
    "        }\n",
    "        all_objs.append(obj)\n",
    "\n",
    "    df = pd.DataFrame(all_objs)\n",
    "\n",
    "    max_dist = max(df[\"max-dist\"])\n",
    "    binaryImage_clRed_mx = np.zeros(label_img.shape, dtype=np.uint8)\n",
    "    for it, region in enumerate(regions):\n",
    "        if df[\"max-dist\"].iloc[it] <= max_dist*0.8:\n",
    "            color_value = 255\n",
    "            binaryImage_clRed_mx[region.coords.T[0], region.coords.T[1]] = color_value\n",
    "    return binaryImage_clRed_mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b05275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmc_model(binaryImage_clRed) -> KMeansConstrained:\n",
    "    cache_path = Path(\"../models/kmc_model_1.pkl\")\n",
    "    cache_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "    if cache_path.exists():\n",
    "        # Load cached model\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            kmc_model = pickle.load(f)\n",
    "        print(\"Loaded cached model from disk.\")\n",
    "    else:\n",
    "        # Train the model\n",
    "        binaryImage_clRed_mx = filter_central_objects(binaryImage_clRed)\n",
    "        kmc_model = cluster_pixels_kmeans_constrained_model(binaryImage_clRed_mx, fraction=10)\n",
    "        # Save to cache\n",
    "        with open(cache_path, \"wb\") as f:\n",
    "            pickle.dump(kmc_model, f)\n",
    "        print(\"Saved trained model to cache.\")\n",
    "        \n",
    "    return kmc_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df97935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_maps_stdev(inputImage_no_gamma):\n",
    "    df = pd.read_csv(\"../data/c_min_k_max_params.csv\")\n",
    "    xs = df[\"clicked_x\"].astype(int)\n",
    "    ys = df[\"clicked_y\"].astype(int)\n",
    "    mean_img, _, _ = data_models.compute_mean_image(inputImage_no_gamma, xs, ys, show_progress=True)\n",
    "    stdev_image = data_models.compute_std_image(inputImage_no_gamma, xs, ys, mean_img, show_progress=True)\n",
    "    return stdev_image / max(stdev_image.flatten()), mean_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_asserts = False\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, model, optimizer, criterion, device: str | torch.device = \"cuda\", channels=3, criterion_kwargs={}):\n",
    "        super().__init__(model, optimizer, criterion, device, criterion_kwargs)\n",
    "        self.channels = channels\n",
    "\n",
    "    def train_epoch_step(self, inputs):\n",
    "        imgs = inputs[0].to(self.device)\n",
    "        if do_asserts: assert (*imgs.shape[1:],) == (self.channels, 101, 101)\n",
    "        imgs = F.interpolate(\n",
    "            imgs, size=(32, 32), mode='bilinear',\n",
    "            align_corners=False)\n",
    "        if do_asserts: assert (*imgs.shape[1:],) == (self.channels, 32, 32)\n",
    "        imgs = imgs.reshape(-1, self.channels*32*32)\n",
    "        if do_asserts: assert (*imgs.shape[1:],) == (self.channels*32*32,)\n",
    "        outputs = self.model(imgs)\n",
    "        return imgs.shape[0], outputs\n",
    "\n",
    "    def train_epoch_loss(self, inputs, outputs):\n",
    "        expected = inputs[1].to(self.device)\n",
    "        expected = torch.squeeze(expected, 1)\n",
    "        expected = torch.squeeze(expected, 2)\n",
    "        if do_asserts: assert (*expected.shape[1:],) == (1,)\n",
    "        loss = self.criterion(outputs, expected, **self.criterion_kwargs)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be902e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(use_selector=False, use_channels=False):\n",
    "\n",
    "    print(\"Starting run...\")\n",
    "    inputImage, inputImage_no_gamma = get_input_image()\n",
    "    \n",
    "    if use_selector or use_channels:\n",
    "        stdev_image, mean_image = get_probability_maps_stdev(inputImage_no_gamma)\n",
    "        #stdev_image = stdev_image / max(stdev_image.flatten())\n",
    "        selector_mask = improc.preprocess_segments(mean_image, area_threshold=0.03, morphological_processing=\"grow\")\n",
    "\n",
    "    print(\"Getting probability maps...\")\n",
    "    if use_selector:\n",
    "        prob_base = stdev_image * selector_mask # pyright: ignore[reportOperatorIssue, reportPossiblyUnboundVariable]\n",
    "    else:\n",
    "        prob_base = get_probability_maps_simple(inputImage)\n",
    "    #\n",
    "\n",
    "    binaryImage_clRed = load_manually_categorized_image()\n",
    "\n",
    "    # Create 8-folds from the probability image\n",
    "    print(\"Loading 8-fold divisions of binaryImage_clRed...\")\n",
    "    kmc_model = get_kmc_model(binaryImage_clRed)\n",
    "\n",
    "    md.set_all_seeds(42)\n",
    "    \n",
    "    centroids = kmc_model.cluster_centers_\n",
    "    regions4 = generate_region_map_from_centroids(np.ones_like(prob_base, dtype=np.uint8), centroids)\n",
    "\n",
    "    #\n",
    "    num_regions = 8\n",
    "\n",
    "    print(\"Creating 8-fold probability masks...\")\n",
    "    from tqdm import tqdm\n",
    "    prob_masks = []\n",
    "    for i in tqdm(range(num_regions)):\n",
    "        mask_i = (regions4 == i).astype(float)\n",
    "        prob_masks.append(prob_base * mask_i)\n",
    "\n",
    "\n",
    "    fold_count = 8\n",
    "    batch_size = 128\n",
    "    num_samples = int(10000/(fold_count - 1)//batch_size*batch_size)\n",
    "\n",
    "    print(f\"num_samples = {num_samples}\")\n",
    "    print(f\"batch_size = {batch_size}\")\n",
    "    print(f\"fold_count = {fold_count}\")\n",
    "\n",
    "    print(\"Adjusting input image...\")\n",
    "    inputImage = inputImage.astype(np.float32)/255.\n",
    "    if use_channels:\n",
    "        mean_image = np.clip(mean_image, 0, 255)/255.\n",
    "        inputImage = np.dstack((inputImage, mean_image, stdev_image)) # pyright: ignore[reportPossiblyUnboundVariable]\n",
    "    \n",
    "    print(\"Creating datasets...\")\n",
    "    datasets = [\n",
    "        ds_models.ProbabilityMapPixelRegionDataset(\n",
    "                prob_map, inputImage, binaryImage_clRed/255.,\n",
    "                num_samples=num_samples,\n",
    "                region_size=101, target_region_size=1, seed=4290\n",
    "            ) for prob_map in prob_masks\n",
    "        ]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(\"Creating models...\")\n",
    "    channels = 3 if not use_channels else 5\n",
    "    models = [nn_models.EncoderNN(initial_dim=channels*32*32).to(device) for _ in range(fold_count)]\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizers = [optim.AdamW(models[it].parameters(),\n",
    "                            lr=1e-4,\n",
    "                            weight_decay=1e-5,\n",
    "                        ) for it in range(fold_count)]\n",
    "    \n",
    "\n",
    "    print(\"Creating trainers...\")\n",
    "    from pre_sal_ii.training import cross_validate\n",
    "    trainers = [MyTrainer(\n",
    "            models[fold],\n",
    "            optimizers[fold],\n",
    "            criterion,\n",
    "            device=device,\n",
    "            channels=channels,\n",
    "        ) for fold in range(fold_count)]\n",
    "    \n",
    "    #\n",
    "    # TRAINING WITH CROSS-VALIDATION AND EARLY STOPPING\n",
    "    #\n",
    "    print(\"Training...\")\n",
    "    best_models, best_losses, best_epochs = cross_validate(\n",
    "        trainers, datasets#, num_epochs=200, patience=15\n",
    "        )\n",
    "\n",
    "    torch.save({\n",
    "        \"models\": [m.state_dict() for m in best_models],\n",
    "        \"fold_losses\": best_losses,\n",
    "        \"epochs\": best_epochs,\n",
    "    }, f\"../models/supervised-8-folds-1.1_selector={use_selector}_channels={use_channels}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(use_selector=True, use_channels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc61919",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(use_selector=True, use_channels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d131304",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(use_selector=False, use_channels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbcd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(use_selector=False, use_channels=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f1721",
   "metadata": {},
   "source": [
    "## Producing images with the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57864163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_images_with_best_models(model_file):\n",
    "    import torch\n",
    "    print(\"Starting run...\")\n",
    "    fold_count = 8\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    use_selector = \"selector=True\" in model_file\n",
    "    use_channels = \"channels=True\" in model_file\n",
    "\n",
    "    channels = 3 if not use_channels else 5\n",
    "    models2 = [nn_models.EncoderNN(initial_dim=channels*32*32).to(device) for _ in range(fold_count)]\n",
    "    checkpoint = torch.load(model_file)\n",
    "    for i, m in enumerate(models2):\n",
    "        m.load_state_dict(checkpoint[\"models\"][i])\n",
    "    fold_losses2 = checkpoint[\"fold_losses\"]\n",
    "    \n",
    "    model = models2[np.argmin(fold_losses2)]\n",
    "\n",
    "    print(\"Getting input images...\")\n",
    "    inputImage, inputImage_no_gamma = get_input_image()\n",
    "    pores_image3 = get_probability_maps_simple(inputImage)\n",
    "    binaryImage_clRed = load_manually_categorized_image()\n",
    "\n",
    "    print(\"Adjusting input image...\")\n",
    "    inputImage = inputImage.astype(np.float32)/255.\n",
    "    if use_channels:\n",
    "        stdev_image, mean_image = get_probability_maps_stdev(inputImage_no_gamma)\n",
    "        #stdev_image = stdev_image / max(stdev_image.flatten())\n",
    "        inputImage = inputImage.astype(np.float32)/255.\n",
    "        inputImage = np.dstack((inputImage, mean_image, stdev_image)) # pyright: ignore[reportPossiblyUnboundVariable]\n",
    "\n",
    "    print(\"Creating dataset...\")\n",
    "    dataset2 = ds_models.WhitePixelRegionDataset(\n",
    "        pores_image3, inputImage, binaryImage_clRed/255.,\n",
    "        num_samples=-1, seed=None, use_img_to_tensor=True)\n",
    "    dataloader2 = DataLoader(dataset2, batch_size=1024, shuffle=False)\n",
    "\n",
    "    trainer_best = MyTrainer(model, None, None, device=device, channels=channels)\n",
    "\n",
    "    print(\"Inferring...\")\n",
    "    pred_image = np.zeros_like(binaryImage_clRed, dtype=np.uint8)\n",
    "\n",
    "    count_gt_half = 0\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    with torch.no_grad():\n",
    "        for it, inputs in enumerate(tqdm(dataloader2)):\n",
    "            _, _, coords = inputs\n",
    "            step, outputs = trainer_best.train_epoch_step(inputs)\n",
    "            Y = outputs\n",
    "\n",
    "            xs = coords[:,1].cpu().numpy()\n",
    "            ys = coords[:,0].cpu().numpy()\n",
    "            vs = Y[:,0].cpu().numpy()\n",
    "            pred_image[ys, xs] = vs*255\n",
    "\n",
    "    print(\"Creating images...\")\n",
    "    plt.imshow(pred_image, vmin=0, vmax=255, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    cv2.imwrite(f\"../out/sup_pred_8fold_1.1_selector={use_selector}_channels={use_channels}.jpg\", pred_image)\n",
    "\n",
    "    image_pred_true = np.zeros([*binaryImage_clRed.shape, 3], dtype=np.uint8)\n",
    "    image_pred_true = torch.tensor(image_pred_true, dtype=torch.uint8).permute(2, 0, 1)\n",
    "    image_pred_true[1,:,:] = torch.tensor(binaryImage_clRed, dtype=torch.uint8)\n",
    "    image_pred_true[2,:,:] = torch.tensor(pred_image, dtype=torch.uint8)\n",
    "    image_pred_true = image_pred_true.permute(1, 2, 0)\n",
    "    image_pred_true = image_pred_true.numpy()\n",
    "    plt.imshow(image_pred_true[:,:,::-1])\n",
    "    plt.show()\n",
    "    cv2.imwrite(f\"../out/image_pred_8fold_true1.1_selector={use_selector}_channels={use_channels}.jpg\", image_pred_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_images_with_best_models(\"../models/supervised-8-folds-1.1_selector=True_channels=True.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_images_with_best_models(\"../models/supervised-8-folds-1.1_selector=True_channels=False.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_images_with_best_models(\"../models/supervised-8-folds-1.1_selector=False_channels=True.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfdf647",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_images_with_best_models(\"../models/supervised-8-folds-1.1_selector=False_channels=False.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4047bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34ec1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fd7735",
   "metadata": {},
   "source": [
    "# Pore type prediction from thin-section images 1.2\n",
    "\n",
    "In this notebook, we get all the code from the 1.0 version, and execute it  many times with multiple parameters combinations.\n",
    "\n",
    "Different from the 1.1 version of this notebook, instead on having the selector and channels as a yes/no answer, we will consider a continuum of powers ranging from 0.0 to 1.0, in intervals of 0.1. This gives us 100 combinations to train and get data from.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077eb077",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import pre_sal_ii.models as models\n",
    "import pre_sal_ii.custom.module1 as m1\n",
    "reload(models)\n",
    "reload(m1)\n",
    "models.set_all_seeds(0)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from pre_sal_ii.improc import generate_region_map_from_centroids\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "import pre_sal_ii.models.nn as nn_models\n",
    "import pre_sal_ii.models.ds as ds_models\n",
    "reload(ds_models)\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import pre_sal_ii.models as md\n",
    "\n",
    "import pre_sal_ii.improc as improc\n",
    "reload(improc)\n",
    "\n",
    "import pre_sal_ii\n",
    "from tqdm.notebook import tqdm\n",
    "pre_sal_ii.progress = tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9924b",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05418b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputImage, inputImage_no_gamma = m1.get_input_image()\n",
    "\n",
    "mean_image, stdev_image = m1.get_mean_stdev(inputImage_no_gamma)\n",
    "stdev_image = stdev_image / max(stdev_image.flatten())\n",
    "\n",
    "plt.imshow(stdev_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2955b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(mean_image.flatten()))\n",
    "print(max(stdev_image.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bebad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_mask = improc.preprocess_segments(\n",
    "    mean_image, area_threshold=0.05, morphological_processing={\"grow\": 25})\n",
    "print(max(selector_mask.flatten()))\n",
    "b = np.clip(mean_image, 0, 255).astype(np.uint8)\n",
    "g = np.clip(selector_mask*255, 0, 255).astype(np.uint8)\n",
    "r = np.zeros_like(g, dtype=np.uint8)\n",
    "plt.imshow(cv2.merge([b, g, r])[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb46101",
   "metadata": {},
   "outputs": [],
   "source": [
    "selmask2 = (selector_mask* 255).astype(np.uint8)\n",
    "print(selmask2.dtype, selmask2.min(), selmask2.max(), selmask2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee7862",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"../out/selector_mask.png\", selmask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((stdev_image*selector_mask)**(1.0 + 0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = 0.5\n",
    "stdev_image2 = stdev_image\n",
    "# stdev_image2 = cv2.normalize(stdev_image2, None, 0.001**(1/power), 1.0, cv2.NORM_MINMAX)\n",
    "stdev_image2 = (stdev_image2)**(power)\n",
    "print(min(stdev_image2.flatten()), max(stdev_image2.flatten()))\n",
    "plt.imshow(stdev_image2)\n",
    "plt.show()\n",
    "plt.hist(stdev_image2.flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e73366",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_base = m1.get_probability_maps_simple(inputImage)\n",
    "plt.imshow(prob_base, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da06ea",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae551f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0001**0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be902e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "            selector_power=0.0, use_channels=False,\n",
    "            stdev_channel_power=0.0, debug=False,\n",
    "            mean_channel_weight=1.0,\n",
    "            stdev_channel_weight=1.0,\n",
    "            color_channels_weight=1.0,\n",
    "            normalize_stdev=True,\n",
    "        ):\n",
    "    \"\"\"\n",
    "     Runs the supervised training with options to use selector mask and additional channels.\n",
    "    \"\"\"\n",
    "\n",
    "    args = f\"_selector_pwr={selector_power:.2f}\"\n",
    "    if use_channels:\n",
    "        args += f\"_channels_pwr={stdev_channel_power:.2f}\"\n",
    "    else:\n",
    "        args += f\"_channels=False\"\n",
    "    if color_channels_weight != 1.0:\n",
    "        args += f\"_color_wt={color_channels_weight:.2f}\"\n",
    "    if mean_channel_weight != 1.0:\n",
    "        args += f\"_mean_wt={mean_channel_weight:.2f}\"\n",
    "    if stdev_channel_weight != 1.0:\n",
    "        args += f\"_stdev_wt={stdev_channel_weight:.2f}\"\n",
    "    if not normalize_stdev:\n",
    "        args += f\"_stdev_norm=False\"\n",
    "    filename = f\"../models/supervised-8-folds-1.2{args}.pt\"\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        return\n",
    "\n",
    "    if debug: print(\"Starting run...\")\n",
    "    inputImage, inputImage_no_gamma = m1.get_input_image()\n",
    "    \n",
    "    mean_image, stdev_image = m1.get_mean_stdev(inputImage_no_gamma)\n",
    "    max_stdev_pixel = max(stdev_image.flatten())\n",
    "    stdev_image = stdev_image / max_stdev_pixel\n",
    "    selector_mask = improc.preprocess_segments(\n",
    "        mean_image, area_threshold=0.03, morphological_processing={\"grow\": 25})\n",
    "    \n",
    "    if debug: print(\"Getting probability maps...\")\n",
    "    prob_base = (stdev_image*selector_mask)**(selector_power + 0.000001) # pyright: ignore[reportOperatorIssue, reportPossiblyUnboundVariable]\n",
    "    #\n",
    "\n",
    "    binaryImage_clRed = m1.load_manually_categorized_image()\n",
    "\n",
    "    # Create 8-folds from the probability image\n",
    "    if debug: print(\"Loading 8-fold divisions of binaryImage_clRed...\")\n",
    "    kmc_model = m1.get_kmc_model(binaryImage_clRed, debug=debug)\n",
    "    \n",
    "    md.set_all_seeds(42)\n",
    "    \n",
    "    centroids = kmc_model.cluster_centers_\n",
    "    regions4 = generate_region_map_from_centroids(np.ones_like(prob_base, dtype=np.uint8), centroids)\n",
    "\n",
    "    #\n",
    "    num_regions = 8\n",
    "\n",
    "    if debug: print(\"Creating 8-fold probability masks...\")\n",
    "    from pre_sal_ii import progress\n",
    "    prob_masks = []\n",
    "    for i in progress(range(num_regions)):\n",
    "        mask_i = (regions4 == i).astype(float)\n",
    "        prob_masks.append(prob_base * mask_i)\n",
    "\n",
    "\n",
    "    fold_count = 8\n",
    "    batch_size = 128\n",
    "    num_samples = int(10000/(fold_count - 1)//batch_size*batch_size)\n",
    "\n",
    "    if debug: print(f\"num_samples = {num_samples}\")\n",
    "    if debug: print(f\"batch_size = {batch_size}\")\n",
    "    if debug: print(f\"fold_count = {fold_count}\")\n",
    "\n",
    "    if debug: print(\"Adjusting input image...\")\n",
    "    inputImage = inputImage.astype(np.float32)*(color_channels_weight/255.0)\n",
    "    if use_channels:\n",
    "        mean_image = np.clip(mean_image, 0, 255)*(mean_channel_weight/255.0)\n",
    "        \n",
    "        stdev_image2 = stdev_image\n",
    "        # stdev_image2 = improc.rescale(stdev_image2, 0.0, 1.0, 0.0001, 1.0)\n",
    "        stdev_image2 = (stdev_image2)**(stdev_channel_power)\n",
    "        stdev_image2 = stdev_image2*stdev_channel_weight\n",
    "        if not normalize_stdev:\n",
    "            stdev_image2 = stdev_image2*(max_stdev_pixel/255.0)\n",
    "\n",
    "        inputImage = np.dstack((inputImage, mean_image, stdev_image2)) # pyright: ignore[reportPossiblyUnboundVariable]\n",
    "\n",
    "    if debug: print(\"Creating datasets...\")\n",
    "    datasets = [\n",
    "        ds_models.ProbabilityMapPixelRegionDataset(\n",
    "                prob_map, inputImage, binaryImage_clRed/255.,\n",
    "                num_samples=num_samples,\n",
    "                region_size=101, target_region_size=1, seed=4290\n",
    "            ) for prob_map in prob_masks\n",
    "        ]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if debug: print(\"Creating models...\")\n",
    "    channels = 3 if not use_channels else 5\n",
    "    models = [nn_models.EncoderNN(initial_dim=channels*32*32).to(device) for _ in range(fold_count)]\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizers = [optim.AdamW(models[it].parameters(),\n",
    "                            lr=1e-4,\n",
    "                            weight_decay=1e-5,\n",
    "                        ) for it in range(fold_count)]\n",
    "    \n",
    "\n",
    "    if debug: print(\"Creating trainers...\")\n",
    "    from pre_sal_ii.training import cross_validate\n",
    "    trainers = [m1.MyTrainer101x101to32x32(\n",
    "            models[fold],\n",
    "            optimizers[fold],\n",
    "            criterion,\n",
    "            device=device,\n",
    "            channels=channels,\n",
    "        ) for fold in range(fold_count)]\n",
    "    \n",
    "    #\n",
    "    # TRAINING WITH CROSS-VALIDATION AND EARLY STOPPING\n",
    "    #\n",
    "    if debug: print(\"Training...\")\n",
    "    best_models, best_losses, best_epochs = cross_validate(\n",
    "        trainers, datasets, num_epochs=200, patience=15,\n",
    "        msg_info=f\"selpwr={selector_power:.2f}_ch={'T' if use_channels else 'F'}{f'_chpwr={stdev_channel_power:.2f}' if use_channels else ''}\",\n",
    "        debug=debug\n",
    "        )\n",
    "\n",
    "    torch.save({\n",
    "        \"models\": [m.state_dict() for m in best_models],\n",
    "        \"fold_losses\": best_losses,\n",
    "        \"epochs\": best_epochs,\n",
    "    }, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5485de63",
   "metadata": {},
   "source": [
    "### Training with a queue (distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316301a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "A = range(11)  # 0 to 10\n",
    "B = range(11)\n",
    "items = list(itertools.product(A, B))\n",
    "\n",
    "url = \"http://localhost:8191/create\"\n",
    "serialized_items = \"\\n\".join(json.dumps(item) for item in items)\n",
    "print(f\"Submitting {len(items)} items to the queue...\")\n",
    "# print(\"  \" + \"\\n  \".join(serialized_items.split(\"\\n\")))\n",
    "response = requests.post(url, data={\"items\": serialized_items})\n",
    "\n",
    "# Check for errors\n",
    "if response.status_code == 200:\n",
    "    guid = response.text.strip()  # The server returns the GUID as plain text\n",
    "    print(\"Queue created with ID:\", guid)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "url = \"http://localhost:8191/\"\n",
    "guid = \"1c6d6274-b07e-492c-90a2-8a4f8f56eeb3\"\n",
    "total_items = 121\n",
    "requests.get(f\"{url}size?id={guid}\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfd847",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = range(11)  # 0 to 10\n",
    "B = range(11)\n",
    "items = list(itertools.product(A, B))\n",
    "\n",
    "for item in items:\n",
    "    i, j = item\n",
    "    filename = f\"../models/supervised-8-folds-1.2_selector_pwr={i/10:.2f}_channels_pwr={j/10:.2f}.pt\"\n",
    "    if os.path.exists(filename):\n",
    "        requests.get(f\"{url}remove?id={guid}&item={json.dumps((i,j))}\").json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pre_sal_ii\n",
    "reload(pre_sal_ii)\n",
    "prev_progress = pre_sal_ii.progress\n",
    "got = None\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    bar = tqdm(total=total_items)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    while True:\n",
    "        # print(\"Fetching next item...\")\n",
    "        response = requests.get(f\"{url}get?id={guid}\")\n",
    "        if response.status_code != 200:\n",
    "            print(\"No more items to process.\")\n",
    "            bar.n = total_items\n",
    "            bar.refresh()\n",
    "            break\n",
    "        # print(\"Received response:\", response.json())\n",
    "        i, j = response.json()\n",
    "        got = (i, j)\n",
    "        bar.set_description(f\"selpwr={i/10:.2f}_ch=True_chpwr={j/10:.2f}\")\n",
    "        missing = requests.get(f\"{url}size?id={guid}\").json()\n",
    "        bar.n = total_items - missing\n",
    "        bar.refresh()\n",
    "        run(selector_power=i/10, use_channels=True, stdev_channel_power=j/10, debug=False)\n",
    "        got = None\n",
    "except Exception as e:\n",
    "    if got is not None:\n",
    "        requests.get(f\"{url}add?id={guid}&item={json.dumps(got)}\").json()\n",
    "    pre_sal_ii.progress = prev_progress\n",
    "    print(f\"Raising exception {e}...\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if got is not None:\n",
    "    requests.get(f\"{url}add?id={guid}&item={json.dumps(got)}\").json()\n",
    "    got = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b6659a",
   "metadata": {},
   "source": [
    "### Training all locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "A = range(11)  # 0 to 10\n",
    "B = range(11)\n",
    "pairs = list(itertools.product(A, B))\n",
    "import pre_sal_ii\n",
    "reload(pre_sal_ii)\n",
    "prev_progress = pre_sal_ii.progress\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    bar = tqdm(pairs)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    for i, j in bar:\n",
    "        bar.set_description(f\"selpwr={i/10:.2f}_ch=True_chpwr={j/10:.2f}\")\n",
    "        run(selector_power=i/10, use_channels=True, stdev_channel_power=j/10, debug=False)\n",
    "except Exception as e:\n",
    "    pre_sal_ii.progress = prev_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "A = range(11)  # 0 to 10\n",
    "B = range(11)\n",
    "pairs = list(itertools.product(A, B))\n",
    "import pre_sal_ii\n",
    "reload(pre_sal_ii)\n",
    "prev_progress = pre_sal_ii.progress\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    bar = tqdm(pairs)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    for i, j in bar:\n",
    "        bar.set_description(f\"selpwr={i/10:.2f}_ch=True_chpwr={j/10:.2f}_mean_wt=255.0\")\n",
    "        run(selector_power=i/10, use_channels=True, stdev_channel_power=j/10,\n",
    "            mean_channel_weight=255.0,\n",
    "            debug=False)\n",
    "except Exception as e:\n",
    "    pre_sal_ii.progress = prev_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4047bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = range(11)  # 0 to 10\n",
    "import pre_sal_ii\n",
    "reload(pre_sal_ii)\n",
    "prev_progress = pre_sal_ii.progress\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    bar = tqdm(A)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    for i in bar:\n",
    "        bar.set_description(f\"selpwr={i/10:.2f}_ch=False\")\n",
    "        run(selector_power=i/10, use_channels=False, debug=False)\n",
    "except Exception as e:\n",
    "    pre_sal_ii.progress = prev_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = range(11)  # 0 to 10\n",
    "import pre_sal_ii\n",
    "reload(pre_sal_ii)\n",
    "prev_progress = pre_sal_ii.progress\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    bar = tqdm(A)\n",
    "    pre_sal_ii.progress = lambda *args, **kwargs: tqdm(*args, leave=False, **kwargs)\n",
    "    for i in bar:\n",
    "        bar.set_description(f\"selpwr={i/10:.2f}_ch=False_mean_wt=255.0\")\n",
    "        run(selector_power=i/10, use_channels=False,\n",
    "            mean_channel_weight=255.0,\n",
    "            debug=False)\n",
    "except Exception as e:\n",
    "    pre_sal_ii.progress = prev_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
